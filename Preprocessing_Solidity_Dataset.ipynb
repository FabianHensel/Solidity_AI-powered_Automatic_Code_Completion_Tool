{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook shows the gathering and preprocessing of Solidity files for the subsequent fine-tuning of a Large Language Model (LLM). A comprehensive preprocessing pipeline consisting of seven steps was created:\n",
    "\n",
    "\n",
    "1. Step \"Cleaning\" - Removes unnecessary parts such as comments or blank lines from each Solidity file.\n",
    "\n",
    "2. Step \"Formatting\" - Converts the code in each file so that the final model only generates code in a correct format. \n",
    "\n",
    "3. Step \"Slither Analysis\" - Checks for vulnerabilities in each Solidity file of the dataset. The files are sorted by the vulnerabilities they contain, and vulnerability annotations are added to the line or construct in which the vulnerability was detected.\n",
    "\n",
    "4. Step \"Splitting\" - Splits each Solidity file according to the definitions (i.e. contract, interface or library) it contains. The required imports are added to the splitted files accordingly.\n",
    "\n",
    "5. Step \"Similarity Check\" - Checks for duplicate and very similar contracts and removes them accordingly.\n",
    "\n",
    "6. Step \"Solhint Fixes\" - Fixes some of the best practice issues detected by Solhint in the Solidity files.\n",
    "\n",
    "7. Step \"Token Insertion\" - Inserts special tokens into each remaining Solidity file that mark the end of a sequence, secure code or fill-in-the-middle (FIM) code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                     # For String manipulation and pattern detection inside Strings\n",
    "import subprocess             # For running console commands inside python (Prettier, Slither, Solhint)\n",
    "import os                     # For plenty of operating system commands\n",
    "import glob\n",
    "import shutil                 # For moving and copying files\n",
    "import random\n",
    "from random import *\n",
    "import json                   # For working with JSON-files\n",
    "import csv                    # For working with CSV-files\n",
    "import requests               # For working with APIs\n",
    "import pandas as pd           # Data science library\n",
    "from concurrent.futures import ThreadPoolExecutor      # For multithreading slow steps (such as slither analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Uncleaned_Datasets/Uncleaned_Dataset_GitHub_06.11.24\"\n",
    "\n",
    "# pragma_0_8_pattern = r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*0\\.8\\.[0-9]+(?:\\s*<\\s*0\\.9\\.0)?;\"\n",
    "\n",
    "# k = 870\n",
    "# for i in range(5000, 60001, 200):\n",
    "#   for j in range(0, 200):\n",
    "#     sol_file = (requests.get(f\"https://scr.ide.tuhh.de/api/contracts?language=Solidity&pragma=0.8.0&size=1000..10000&limit=200&skip={i}\").json()['data'][j]['versions'][0]['content'])\n",
    "#     if \"import\" in sol_file or \"assembly\" in sol_file:\n",
    "#       pass\n",
    "#     elif re.search(pragma_0_8_pattern, sol_file) and \"contract\" in sol_file:\n",
    "#       with open(os.path.join(save_path, f\"solidity_code_{k}.sol\"), \"w\", encoding='utf-8') as file:\n",
    "#         file.write(sol_file)\n",
    "#       k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etherscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_19_11 = pd.read_csv(\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Uncleaned_Datasets/Uncleaned_Dataset_Etherscan_19.11.24/verified_etherscan_contracts_(19.11.24).csv\", usecols=[1])\n",
    "\n",
    "# api_key = \"EAB5Y8CCNUEVH1ATFUN1IBBXQTT74322DV\"\n",
    "\n",
    "# contractAddress_19_11 = data_19_11.iloc[1:, 0]\n",
    "\n",
    "# save_path_19_11 = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Uncleaned_Datasets/Uncleaned_Dataset_Etherscan_19.11.24\"\n",
    "\n",
    "# j = 1\n",
    "# for i in range(1, 5001):\n",
    "#     sol_file = requests.get(f\"https://api.etherscan.io/api?module=contract&action=getsourcecode&address={contractAddress_19_11[i]}&apikey={api_key}\").json()[\"result\"][0][\"SourceCode\"]\n",
    "#     if sol_file[0] == \"{\" or sol_file[0] == \"#\":\n",
    "#         pass\n",
    "#     else:\n",
    "#         with open(os.path.join(save_path_19_11, f\"solidity_code_{j}.sol\"), \"w\", encoding='utf-8') as file:\n",
    "#             file.write(sol_file)\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"ASSERT-KTH/DISL\", \"decompose\", split=\"test\")\n",
    "\n",
    "# pragma_0_8_pattern = r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*0\\.8\\.[0-9]+(?:\\s*<\\s*0\\.9\\.0)?;\"\n",
    "# save_path = \"/content/drive/MyDrive/Colab_Notebooks_2/DISL_Contracts/\"\n",
    "\n",
    "# k = 1\n",
    "# for i in range(0, len(dataset[\"train\"])):\n",
    "#   sol_file = dataset[\"train\"][i]['source_code']\n",
    "#   if \"import\" in sol_file:\n",
    "#     pass\n",
    "#   elif re.search(pragma_0_8_pattern, sol_file) and \"contract\" in sol_file:\n",
    "#     with open(os.path.join(save_path, f\"solidity_code_{k}.sol\"), \"w\", encoding='utf-8') as file:\n",
    "#       file.write(sol_file)\n",
    "#     k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just there to count how much contracts were removed during this step\n",
    "count = 0\n",
    "\n",
    "# Cleans the contract, i.e., unnecessary comments are removed and so on.\n",
    "def clean_contract(path_r, path_w):\n",
    "    with open(path_r, \"r\", encoding='utf-8') as file:    # utf-8 encoding is necessary as some contracts have special characters in their comments\n",
    "        cleaned_code = file.read()\n",
    "\n",
    "    directory_length = len(os.listdir(path_w))\n",
    "\n",
    "    pragma_0_8_pattern = r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*0\\.8\\.[0-9]+(?:\\s*<\\s*0\\.9\\.0)?;\"\n",
    "    pragma_0_7_below_pattern = r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*[0-9]+\\.[0-7]+\\.[0-9]+(?:\\s*<\\s*0\\.[0-9]+\\.[0-9])?;\"\n",
    "    \n",
    "    if re.search(pragma_0_8_pattern, cleaned_code) and not re.search(pragma_0_7_below_pattern, cleaned_code):     # Sometimes there are different pragmas in one file, only pragma ^0.8.0 should be recognized\n",
    "        # Inserts a space between // and the SPDX-License-Identifier. In some contracts this is not the case\n",
    "        cleaned_code = re.sub(r'//SPDX-License-Identifier:', '// SPDX-License-Identifier:', cleaned_code)\n",
    "\n",
    "        # Searches for the \"// SPDX-License-Identifier\" line in the contract (no matter if at the beginning or below some other comments) and stores it \n",
    "        spdx_pattern = r\"^// SPDX-License-Identifier: .*$\"\n",
    "        spdx_matches = re.findall(spdx_pattern, cleaned_code, re.MULTILINE)  \n",
    "\n",
    "        # Removes import statements\n",
    "        # cleaned_code = re.sub(r\"import [^{};]*\\;\", \"\", cleaned_code)\n",
    "    \n",
    "        # Removes pragma directives except for the solidity pragma\n",
    "        cleaned_code = re.sub(r\"pragma\\s+experimental.*?;\\n\", \"\", cleaned_code)\n",
    "\n",
    "        # Normalizes the solidity pragma to a standard version\n",
    "        cleaned_code = re.sub(r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*[0-9]+\\.[0-9]+\\.[0-9]+(?:\\s*<\\s*[0-9]+\\.[0-9]+\\.[0-9])?;\", \"\", cleaned_code)\n",
    "        cleaned_code = \"pragma solidity ^0.8.0;\" + \"\\n\" + cleaned_code\n",
    "\n",
    "        # Removes single-line comments, but only if they are not inside strings \"\" or ''  \n",
    "        lines = cleaned_code.splitlines()\n",
    "        cleaned_lines = []\n",
    "        single_line_comment_pattern = r\"//.*\"\n",
    "        for line in lines:\n",
    "            if is_in_string(line):\n",
    "                cleaned_lines.append(line)\n",
    "            else:\n",
    "                line = re.sub(single_line_comment_pattern, \"\", line)\n",
    "                cleaned_lines.append(line)\n",
    "\n",
    "        cleaned_code = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "        # Removes long comment blocks\n",
    "        cleaned_code = re.sub(r\"/\\*.*?\\*/\", \"\", cleaned_code, flags=re.DOTALL)    # re.DOTALL deletes also line breaks, i.e., whole blocks\n",
    "\n",
    "        # Inserts the \"// SPDX-License-Identifier\" with corresponding license back into the contract\n",
    "        if spdx_matches:\n",
    "            # In some contracts are more than one SPDX line, therefore use only the first in the matching list\n",
    "            spdx_line = spdx_matches[0]\n",
    "            if not cleaned_code.startswith(spdx_line):\n",
    "                cleaned_code = spdx_line + \"\\n\" + cleaned_code\n",
    "        else:\n",
    "            # Sometimes no License-Identfier is given, hence UNLICENSE is added\n",
    "            cleaned_code = \"// SPDX-License-Identifier: UNLICENSE\" + \"\\n\" + cleaned_code\n",
    "\n",
    "        file_name = os.path.basename(path_r)\n",
    "        output_file = os.path.join(path_w, file_name)\n",
    "        # output_file = os.path.join(path_w, f\"solidity_code_{1+directory_length}.sol\")\n",
    "        with open(output_file, \"w\", encoding='utf-8') as file:\n",
    "            file.write(cleaned_code)\n",
    "    \n",
    "    else:\n",
    "        global count\n",
    "        count += 1\n",
    "        file_name = os.path.basename(path_r)\n",
    "        print(f\"Deleted {file_name} | Deleted files: {count}\")\n",
    "        pass\n",
    "\n",
    "# This function is required to check whether the line contains a string or not\n",
    "def is_in_string(line):\n",
    "    # Count occurrences of double and single quotes and comment signs\n",
    "    double_quotes = line.count('\"')\n",
    "    single_quotes = line.count(\"'\")\n",
    "    comment = line.count(\"//\")\n",
    "\n",
    "    # Removes every space, this is necessary for the startswith() check\n",
    "    line = \"\".join(line.split())\n",
    "\n",
    "    # If there are two double or single quotes and the line starts not with /, then it's a string\n",
    "    return ((double_quotes % 3 == 2) and (comment % 2 == 1) and not line.startswith('/')) or ((single_quotes % 3 == 2) and (comment % 2 == 1) and not line.startswith('/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset\"\n",
    "\n",
    "solidity_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "\n",
    "for file in solidity_files:\n",
    "    clean_contract(f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset/{file}\",\n",
    "                   \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Without_Imports-Pragmas-SPDX\")\n",
    "\n",
    "# for i in range(1, 4572):\n",
    "#     clean_contract(f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Uncleaned_Datasets/Uncleaned_Dataset_Etherscan_25.11.24/solidity_code_{i}.sol\",\n",
    "#                    f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Cleaned_Datasets/Etherscan_25.11.24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Test3\"\n",
    "\n",
    "# Formats a solidity smart contract using Prettier and the corresponing plugin \"prettier-plugin-solidity\"\n",
    "def format_contract(file_name):\n",
    "    # folder_path = os.path.dirname(file_path)\n",
    "    # file_name = os.path.basename(file_path)\n",
    "    try:\n",
    "        # With \"subprocess\" one can execute console commands in python\n",
    "        subprocess.run([\"C:/Users/Fabian Hensel/AppData/Roaming/npm/prettier.cmd\", \"--write\", \"--plugin=prettier-plugin-solidity\", file_name], check=True, cwd=folder_path)\n",
    "        # print(f\"Formatted {file_name} successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"{file_name} deleted!\")\n",
    "        else:\n",
    "            print(f\"{file_name} not found.\")\n",
    "        print(f\"Error formatting {file_name}: {e}\")\n",
    "\n",
    "\n",
    "# Runs the prettier formatting parallel\n",
    "def run_prettier_parallel(path_r):\n",
    "    contract_files = os.listdir(path_r)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        executor.map(format_contract, contract_files)\n",
    "\n",
    "    print(\"Parallel formatting completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prettier_parallel(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Slither Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just there to count how much contracts were removed during this step\n",
    "count = 0\n",
    "\n",
    "# Always installs the newest available solc version\n",
    "subprocess.run([\"solc-select\", \"use\", \"--always-install\", \"0.8.28\"])\n",
    "\n",
    "unchecked_contracts_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Cleaned_Datasets/DISL_27.11.24/contracts_8\" \n",
    "# Splits the path into components\n",
    "path_parts = os.path.normpath(unchecked_contracts_dir).split(os.sep)\n",
    "# Gets the last two components\n",
    "last_two_folders = path_parts[-3:]\n",
    "\n",
    "low_vulnerability_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Low\" \n",
    "medium_vulnerability_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Medium\"\n",
    "high_vulnerability_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/High\"\n",
    "\n",
    "secure_optimized_contracts_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Secure\"\n",
    "secure_contracts_dir = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Opt_Issue\"\n",
    "\n",
    "# A dictionary of the slither detectors and the corresponding description and recommendation how to avoid the vulnerability\n",
    "slither_vulnerabilities_and_optimizations = {\n",
    "    \"abiencoderv2-array\": {\n",
    "        \"description\": \"'solc' versions '0.4.7-0.5.9' contain a compiler bug leading to incorrect ABI encoder usage.\",\n",
    "        \"recommendation\": \"Use a compiler >= '0.5.10'.\"\n",
    "    },\n",
    "\n",
    "    \"arbitrary-send-erc20\": {\n",
    "        \"description\": \"'msg.sender' is not used as 'from' in 'transferFrom'.\",\n",
    "        \"recommendation\": \"Use 'msg.sender' as 'from' in 'transferFrom'.\"\n",
    "    },\n",
    "\n",
    "    \"array-by-reference\": {\n",
    "        \"description\": \"Arrays passed to a function that expects reference to a storage array.\",\n",
    "        \"recommendation\": \"Ensure the correct usage of 'memory' and 'storage' in the function parameters. Make all the locations explicit.\"\n",
    "    },\n",
    "\n",
    "    \"encode-packed-collision\": {\n",
    "        \"description\": \"Collision due to dynamic type usages in 'abi.encodePacked'.\",\n",
    "        \"recommendation\": \"Do not use more than one dynamic type in 'abi.encodePacked()' (see the Solidity documentation). Use 'abi.encode()', preferably.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-shift\": {\n",
    "        \"description\": \"Values in the shift operation are reversed.\",\n",
    "        \"recommendation\": \"Swap the order of parameters.\"\n",
    "    },\n",
    "\n",
    "    \"multiple-constructors\": {\n",
    "        \"description\": \"Multiple constructor definitions in the same contract (using new and old schemes).\",\n",
    "        \"recommendation\": \"Only declare one constructor, preferably using the new scheme 'constructor(...)' instead of 'function <contractName>(...)'.\"\n",
    "    },\n",
    "\n",
    "    \"name-reused\": {\n",
    "        \"description\": \"Codebase has two contracts with similar names, the compilation artifacts will not contain one of the contracts with the duplicate name.\",\n",
    "        \"recommendation\": \"Rename the contract.\"\n",
    "    },\n",
    "\n",
    "    \"protected-vars\": {\n",
    "        \"description\": \"Unprotected variable that is marked as protected.\",\n",
    "        \"recommendation\": \"Add access controls to the vulnerable function.\"\n",
    "    },\n",
    "\n",
    "    \"public-mappings-nested\": {\n",
    "        \"description\": \"Prior to Solidity 0.5, a public mapping with nested structures returned incorrect values.\",\n",
    "        \"recommendation\": \"Do not use public mapping with nested structures.\"\n",
    "    },\n",
    "\n",
    "    \"rtlo\": {\n",
    "        \"description\": \"An attacker can manipulate the logic of the contract by using a right-to-left-override character '(U+202E)'.\",\n",
    "        \"recommendation\": \"Special control characters must not be allowed.\"\n",
    "    },\n",
    "\n",
    "    \"shadowing-state\": {\n",
    "        \"description\": \"Shadowed state variables. 'owner' of 'BaseContract' is never assigned and the modifier 'isOwner' does not work.\",\n",
    "        \"recommendation\": \"Remove the state variable shadowing.\"\n",
    "    },\n",
    "\n",
    "    \"suicidal\": {\n",
    "        \"description\": \"Unprotected call to a function executing 'selfdestruct'/'suicide'.\",\n",
    "        \"recommendation\": \"Protect access to all sensitive functions.\"\n",
    "    },\n",
    "\n",
    "    \"uninitialized-state\": {\n",
    "        \"description\": \"Uninitialized state variables\",\n",
    "        \"recommendation\": \"Initialize all the variables. If a variable is meant to be initialized to zero, explicitly set it to zero to improve code readability.\"\n",
    "    },\n",
    "\n",
    "    \"uninitialized-storage\": {\n",
    "        \"description\": \"An uninitialized storage variable will act as a reference to the first state variable, and can override a critical variable.\",\n",
    "        \"recommendation\": \"Initialize all storage variables.\"\n",
    "    },\n",
    "\n",
    "    \"unprotected-upgrade\": {\n",
    "        \"description\": \"Logic contract that can be destructed.\",\n",
    "        \"recommendation\": \"Add a constructor to ensure 'initialize' cannot be called on the logic contract.\"\n",
    "    },\n",
    "\n",
    "    \"arbitrary-send-erc20-permit\": {\n",
    "        \"description\": \"'msg.sender' is not used as 'from' in 'transferFrom' and permit is used.\",\n",
    "        \"recommendation\": \"Ensure that the underlying ERC20 token correctly implements a permit function.\"\n",
    "    },\n",
    "\n",
    "    \"arbitrary-send-eth\": {\n",
    "        \"description\": \"Unprotected call to a function sending Ether to an arbitrary address.\",\n",
    "        \"recommendation\": \"Ensure that an arbitrary user cannot withdraw unauthorized funds.\"\n",
    "    },\n",
    "\n",
    "    \"controlled-array-length\": {\n",
    "        \"description\": \"Direct assignment of an array's length.\",\n",
    "        \"recommendation\": \"Do not allow array lengths to be set directly; instead, add values as needed. Otherwise, thoroughly review the contract to ensure a user-controlled variable cannot reach an array length assignment.\"\n",
    "    },\n",
    "\n",
    "    \"controlled-delegatecall\": {\n",
    "        \"description\": \"'delegatecall' or 'callcode' to an address controlled by the user.\",\n",
    "        \"recommendation\": \"Avoid using 'delegatecall'. Use only trusted destinations.\"\n",
    "    },\n",
    "\n",
    "    \"delegatecall-loop\": {\n",
    "        \"description\": \"Use of 'delegatecall' inside a loop in a payable function.\",\n",
    "        \"recommendation\": \"Carefully check that the function called by 'delegatecall' is not payable/doesn't use 'msg.value'.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-exp\": {\n",
    "        \"description\": \"Use of bitwise 'xor ^' instead of exponential '**'.\",\n",
    "        \"recommendation\": \"Use the correct operator '**' for exponentiation.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-return\": {\n",
    "        \"description\": \"'return' in an assembly block halts unexpectedly the execution.\",\n",
    "        \"recommendation\": \"Use the 'leave' statement.\"\n",
    "    },\n",
    "\n",
    "    \"msg-value-loop\": {\n",
    "        \"description\": \"Use of 'msg.value' inside a loop.\",\n",
    "        \"recommendation\": \"Provide an explicit array of amounts alongside the receivers array, and check that the sum of all amounts matches 'msg.value'.\"\n",
    "    },\n",
    "\n",
    "    \"reentrancy-eth\": {\n",
    "        \"description\": \"Reentrancy bug (see 'https://github.com/crytic/not-so-smart-contracts/tree/master/reentrancy'). Do not report reentrancies that don't involve Ether.\",\n",
    "        \"recommendation\": \"Apply the check-effects-interactions pattern (see 'https://docs.soliditylang.org/en/v0.4.21/security-considerations.html#re-entrancy').\"\n",
    "    },\n",
    "\n",
    "    \"return-leave\": {\n",
    "        \"description\": \"A 'return' is used where a 'leave' should be used.\",\n",
    "        \"recommendation\": \"Use the 'leave' statement.\"\n",
    "    },\n",
    "\n",
    "    \"storage-array\": {\n",
    "        \"description\": \"'solc' versions '0.4.7-0.5.9' contain a compiler bug leading to incorrect values in signed integer arrays.\",\n",
    "        \"recommendation\": \"Use a compiler version >= '0.5.10'.\"\n",
    "    },\n",
    "\n",
    "    \"unchecked-transfer\": {\n",
    "        \"description\": \"The return value of an external 'transfer'/'transferFrom' call is not checked.\",\n",
    "        \"recommendation\": \"Use 'SafeERC20', or ensure that the 'transfer'/'transferFrom' return value is checked.\"\n",
    "    },\n",
    "\n",
    "    \"weak-prng\": {\n",
    "        \"description\": \"Weak PRNG (Pseudo Random Number Generator) due to a modulo on 'block.timestamp', 'now' or 'blockhash'. These can be influenced by miners to some extent.\",\n",
    "        \"recommendation\": \"Do not use 'block.timestamp', 'now' or 'blockhash' as a source of randomness.\"\n",
    "    },\n",
    "\n",
    "    \"codex\": {\n",
    "        \"description\": \"Use codex (see 'https://openai.com/index/openai-codex/') to find vulnerabilities.\",\n",
    "        \"recommendation\": \"Review codex's message.\"\n",
    "    },\n",
    "\n",
    "    \"domain-separator-collision\": {\n",
    "        \"description\": \"An ERC20 token has a function whose signature collides with EIP-2612's 'DOMAIN_SEPARATOR()', causing unanticipated behavior for contracts using 'permit' functionality.\",\n",
    "        \"recommendation\": \"Remove or rename the function that collides with 'DOMAIN_SEPARATOR()'.\"\n",
    "    },\n",
    "\n",
    "    \"enum-conversion\": {\n",
    "        \"description\": \"Out-of-range 'enum' conversion ('solc' < '0.4.5').\",\n",
    "        \"recommendation\": \"Use a recent compiler version. If 'solc' < '0.4.5' is required, check the 'enum' conversion range.\"\n",
    "    },\n",
    "\n",
    "    \"erc20-interface\": {\n",
    "        \"description\": \"Incorrect return values for 'ERC20' functions. A contract compiled with Solidity > '0.4.22' interacting with these functions will fail to execute them, as the return value is missing.\",\n",
    "        \"recommendation\": \"Set the appropriate return values and types for the defined 'ERC20' functions.\"\n",
    "    },\n",
    "\n",
    "    \"erc721-interface\": {\n",
    "        \"description\": \"Incorrect return values for 'ERC721' functions. A contract compiled with solidity > '0.4.22' interacting with these functions will fail to execute them, as the return value is missing.\",\n",
    "        \"recommendation\": \"Set the appropriate return values and vtypes for the defined 'ERC721' functions.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-equality\": {\n",
    "        \"description\": \"Use of strict equalities that can be easily manipulated by an attacker.\",\n",
    "        \"recommendation\": \"Don't use strict equality to determine if an account has enough Ether or tokens.\"\n",
    "    },\n",
    "\n",
    "    \"locked-ether\": {\n",
    "        \"description\": \"Contract with a 'payable' function, but without a withdrawal capacity.\",\n",
    "        \"recommendation\": \"Remove the 'payable' attribute or add a withdraw function.\"\n",
    "    },\n",
    "\n",
    "    \"mapping-deletion\": {\n",
    "        \"description\": \"A deletion in a structure containing a mapping will not delete the mapping (see the Solidity documentation). The remaining data may be used to compromise the contract.\",\n",
    "        \"recommendation\": \"Use a lock mechanism instead of a deletion to disable structure containing a mapping.\"\n",
    "    },\n",
    "\n",
    "    \"shadowing-abstract\": {\n",
    "        \"description\": \"State variables shadowed from abstract contracts.\",\n",
    "        \"recommendation\": \"Remove the state variable shadowing.\"\n",
    "    },\n",
    "\n",
    "    \"tautological-compare\": {\n",
    "        \"description\": \"A variable compared to itself is probably an error as it will always return 'true' for '==', '>=', '<=' and always 'false' for '<', '>' and '!='.\",\n",
    "        \"recommendation\": \"Remove comparison or compare to different value.\"\n",
    "    },\n",
    "\n",
    "    \"tautology\": {\n",
    "        \"description\": \"Expressions that are tautologies or contradictions.\",\n",
    "        \"recommendation\": \"Fix the incorrect comparison by changing the value type or the comparison.\"\n",
    "    },\n",
    "\n",
    "    \"write-after-write\": {\n",
    "        \"description\": \"Variables that are written but never read and written again.\",\n",
    "        \"recommendation\": \"Fix or remove the writes.\"\n",
    "    },\n",
    "\n",
    "    \"boolean-cst\": {\n",
    "        \"description\": \"Misuse of a Boolean constant.\",\n",
    "        \"recommendation\": \"Verify and simplify the condition.\"\n",
    "    },\n",
    "\n",
    "    \"constant-function-asm\": {\n",
    "        \"description\": \"Functions declared as constant/pure/view using assembly code. A call to an incorrectly labeled function may trap a contract compiled with Solidity 0.5.\",\n",
    "        \"recommendation\": \"Ensure the attributes of contracts compiled prior to Solidity 0.5.0 are correct.\"\n",
    "    },\n",
    "\n",
    "    \"constant-function-state\": {\n",
    "        \"description\": \"Functions declared as constant/pure/view change the state. A call to an incorrectly labeled function may trap a contract compiled with Solidity 0.5.\",\n",
    "        \"recommendation\": \"Ensure that attributes of contracts compiled prior to Solidity 0.5.0 are correct.\"\n",
    "    },\n",
    "\n",
    "    \"divide-before-multiply\": {\n",
    "        \"description\": \"Solidity's integer division truncates. Thus, performing division before multiplication can lead to precision loss.\",\n",
    "        \"recommendation\": \"Consider ordering multiplication before division.\"\n",
    "    },\n",
    "\n",
    "    \"out-of-order-retryable\": {\n",
    "        \"description\": \"Out-of-order retryable transactions.\",\n",
    "        \"recommendation\": \"Do not rely on the order or successful execution of retryable tickets.\"\n",
    "    },\n",
    "\n",
    "    \"reentrancy-no-eth\": {\n",
    "        \"description\": \"Reentrancy bug (see 'https://github.com/crytic/not-so-smart-contracts/tree/master/reentrancy'). Do not report reentrancies that involve Ether.\",\n",
    "        \"recommendation\": \"Apply the check-effects-interactions pattern (see 'https://docs.soliditylang.org/en/v0.4.21/security-considerations.html#re-entrancy').\"\n",
    "    },\n",
    "\n",
    "    \"reused-constructor\": {\n",
    "        \"description\": \"The same base constructor is called with arguments from two different locations in the same inheritance hierarchy.\",\n",
    "        \"recommendation\": \"Remove the duplicate constructor call.\"\n",
    "    },\n",
    "\n",
    "    \"tx-origin\": {\n",
    "        \"description\": \"'tx.origin'-based protection can be abused by a malicious contract if a legitimate user interacts with the malicious contract.\",\n",
    "        \"recommendation\": \"Do not use 'tx.origin' for authorization.\"\n",
    "    },\n",
    "\n",
    "    \"unchecked-lowlevel\": {\n",
    "        \"description\": \"The return value of a low-level call is not checked.\",\n",
    "        \"recommendation\": \"Ensure that the return value of a low-level call is checked or logged.\"\n",
    "    },\n",
    "\n",
    "    \"unchecked-send\": {\n",
    "        \"description\": \"The return value of a 'send' is not checked.\",\n",
    "        \"recommendation\": \"Ensure that the return value of 'send' is checked or logged.\"\n",
    "    },\n",
    "\n",
    "    \"uninitialized-local\": {\n",
    "        \"description\": \"Uninitialized local variables.\",\n",
    "        \"recommendation\": \"Initialize all the variables. If a variable is meant to be initialized to zero, explicitly set it to zero to improve code readability.\"\n",
    "    },\n",
    "\n",
    "    \"unused-return\": {\n",
    "        \"description\": \"The return value of an external call is not stored in a local or state variable.\",\n",
    "        \"recommendation\": \"Ensure that all the return values of the function calls are used.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-modifier\": {\n",
    "        \"description\": \"If a modifier does not execute '_' or revert, the execution of the function will return the default value, which can be misleading for the caller.\",\n",
    "        \"recommendation\": \"All the paths in a modifier must execute '_' or revert.\"\n",
    "    },\n",
    "\n",
    "    \"shadowing-builtin\": {\n",
    "        \"description\": \"Shadowing built-in symbols using local variables, state variables, functions, modifiers, or events.\",\n",
    "        \"recommendation\": \"Rename the local variables, state variables, functions, modifiers, and events that shadow a builtin symbol.\"\n",
    "    },\n",
    "\n",
    "    \"shadowing-local\": {\n",
    "        \"description\": \"Shadowing using local variables.\",\n",
    "        \"recommendation\": \"Rename the local variables that shadow another component.\"\n",
    "    },\n",
    "\n",
    "    \"uninitialized-fptr-cst\": {\n",
    "        \"description\": \"'solc' versions '0.4.5-0.4.26' and '0.5.0-0.5.8' contain a compiler bug leading to unexpected behavior when calling uninitialized function pointers in constructors.\",\n",
    "        \"recommendation\": \"Initialize function pointers before calling. Avoid function pointers if possible.\"\n",
    "    },\n",
    "\n",
    "    \"variable-scope\": {\n",
    "        \"description\": \"Usage of a variable before the declaration is stepped over.\",\n",
    "        \"recommendation\": \"Move all variable declarations prior to any usage of the variable, and ensure that reaching a variable declaration does not depend on some conditional if it is used unconditionally.\"\n",
    "    },\n",
    "\n",
    "    \"void-cst\": {\n",
    "        \"description\": \"Call to a constructor that is not implemented.\",\n",
    "        \"recommendation\": \"Remove the constructor call.\"\n",
    "    },\n",
    "\n",
    "    \"calls-loop\": {\n",
    "        \"description\": \"Calls inside a loop might lead to a denial-of-service attack.\",\n",
    "        \"recommendation\": \"Favor pull over push strategy for external calls.\"\n",
    "    },\n",
    "\n",
    "    \"events-access\": {\n",
    "        \"description\": \"Missing events for critical access control parameters.\",\n",
    "        \"recommendation\": \"Emit an event for critical parameter changes.\"\n",
    "    },\n",
    "\n",
    "    \"events-maths\": {\n",
    "        \"description\": \"Missing events for critical arithmetic parameters.\",\n",
    "        \"recommendation\": \"Emit an event for critical parameter changes.\"\n",
    "    },\n",
    "\n",
    "    \"incorrect-unary\": {\n",
    "        \"description\": \"Unary expressions such as 'x=+1' probably typos.\",\n",
    "        \"recommendation\": \"Remove the unary expression.\"\n",
    "    },\n",
    "\n",
    "    \"missing-zero-check\": {\n",
    "        \"description\": \"Missing zero address validation.\",\n",
    "        \"recommendation\": \"Check that the address is not zero.\"\n",
    "    },\n",
    "\n",
    "    \"reentrancy-benign\": {\n",
    "        \"description\": \"Reentrancy bug (see 'https://github.com/crytic/not-so-smart-contracts/tree/master/reentrancy'). Only report reentrancy that acts as a double call.\",\n",
    "        \"recommendation\": \"Apply the check-effects-interactions pattern (see 'https://docs.soliditylang.org/en/v0.4.21/security-considerations.html#re-entrancy').\"\n",
    "    },\n",
    "\n",
    "    \"reentrancy-events\": {\n",
    "        \"description\": \"Reentrancies (see 'https://github.com/crytic/not-so-smart-contracts/tree/master/reentrancy') that allow manipulation of the order or value of events.\",\n",
    "        \"recommendation\": \"Apply the check-effects-interactions pattern (see 'https://docs.soliditylang.org/en/v0.4.21/security-considerations.html#re-entrancy').\"\n",
    "    },\n",
    "\n",
    "    \"return-bomb\": {\n",
    "        \"description\": \"A low level callee may consume all callers gas unexpectedly.\",\n",
    "        \"recommendation\": \"Avoid unlimited implicit decoding of returndata.\"\n",
    "    },\n",
    "\n",
    "    \"timestamp\": {\n",
    "        \"description\": \"Dangerous usage of 'block.timestamp'. 'block.timestamp' can be manipulated by miners.\",\n",
    "        \"recommendation\": \"Avoid relying on 'block.timestamp'.\"\n",
    "    },\n",
    "\n",
    "    \"cache-array-length\": {\n",
    "        \"description\": \"'for' loops that use 'length' member of some storage array in their loop condition and don't modify it.\",\n",
    "        \"recommendation\": \"Cache the lengths of storage arrays if they are used and not modified in 'for' loops.\"\n",
    "    },\n",
    "\n",
    "    \"constable-states\": {\n",
    "        \"description\": \"State variables that are not updated following deployment should be declared 'constant' to save gas.\",\n",
    "        \"recommendation\": \"Add the 'constant' attribute to state variables that never change.\"\n",
    "    },\n",
    "\n",
    "    \"external-function\": {\n",
    "        \"description\": \"'public' functions that are never called by the contract should be declared 'external', and its immutable parameters should be located in 'calldata' to save gas.\",\n",
    "        \"recommendation\": \"Use the 'external' attribute for functions never called from the contract, and change the location of immutable parameters to 'calldata' to save gas.\"\n",
    "    },\n",
    "\n",
    "    \"immutable-states\": {\n",
    "        \"description\": \"State variables that are not updated following deployment should be declared 'immutable' to save gas.\",\n",
    "        \"recommendation\": \"Add the 'immutable' attribute to state variables that never change or are set only in the constructor.\"\n",
    "    },\n",
    "\n",
    "    \"var-read-using-this\": {\n",
    "        \"description\": \"The contract reads its own variable using 'this', adding overhead of an unnecessary STATICCALL.\",\n",
    "        \"recommendation\": \"Read the variable directly from storage instead of calling the contract.\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# This function annotates the vulnerabilities in the sol code with comments\n",
    "def insert_comments_with_position(code_lines, issues):\n",
    "    # Sorts the issues by lines for correct insertion\n",
    "    issues_sorted = sorted(issues, key=lambda x: x['line'], reverse=True)\n",
    "\n",
    "    # Calculates the tabs which are used in the line which has to be commented\n",
    "    tabs = [{\n",
    "        \"tabs\": (len(code_lines[issue['line']-1]) - len(code_lines[issue['line']-1].lstrip(' '))) // 4,\n",
    "        \"tabs_parent\": (len(code_lines[issue['parent_line']-1]) - len(code_lines[issue['parent_line']-1].lstrip(' '))) // 4\n",
    "    } for issue in issues_sorted]\n",
    "\n",
    "    # Inserts comments from below to above to avoid line shifts\n",
    "    for i, issue in enumerate(issues_sorted):\n",
    "        line_num = issue['line'] - 1 \n",
    "        comment = \"\"\n",
    "\n",
    "        # If the slither analysis description is less than 200 characters (see 1) it is preferred before the description of the dictionary\n",
    "        description = re.sub(rf\"\\s*\\({last_two_folders[0]}/{last_two_folders[1]}/{last_two_folders[2]}/.*?\\)\", \"\", issue['description'])\n",
    "\n",
    "        # As the code will be splitted later on, issue annotations in libraries or interfaces are unnecessary\n",
    "        if issue['parent_name'] == \"Ownable\" or issue['parent_name'] == \"ERC20\" or issue['parent_name'] == \"IERC20Metadata\" or issue['parent_name'] == \"Context\":\n",
    "            continue\n",
    "\n",
    "        if issue['construct'] == \"function\" or issue['construct'] == \"contract\" or (issue['construct'] == \"variable\" and issue['parent_construct'] == \"contract\"):\n",
    "            if issue['severity'] == \"High\" or issue['severity'] == \"Medium\" or issue['severity'] == \"Low\":  \n",
    "                # Warning: (severity: low/medium/high/optimization): Description of Vulnerability\n",
    "                if len(description) < 200:   # 1\n",
    "                    comment1 = f\"// WARNING Vulnerability ({issue['type']} | severity: {issue['severity']} | ID: {issue['id']}): {description}\"\n",
    "                else:\n",
    "                    comment1 = f\"// WARNING Vulnerability ({issue['type']} | severity: {issue['severity']} | ID: {issue['id']}): {slither_vulnerabilities_and_optimizations[issue['type']]['description']}\\n\"\n",
    "                # Recommendation how to avoid Vulnerability\n",
    "                comment2 = f\"// Recommendation for {issue['id']}: {slither_vulnerabilities_and_optimizations[issue['type']]['recommendation']}\"\n",
    "                comment = (tabs[i].get(\"tabs\")*\"\\t\") + comment1 + (tabs[i].get(\"tabs\")*\"\\t\") + comment2 + \"\\n\"\n",
    "\n",
    "            elif issue['severity'] == \"Optimization\":\n",
    "                comment1 = f\"// WARNING Optimization Issue ({issue['type']} | ID: {issue['id']}): {description}\"\n",
    "                comment2 = f\"// Recommendation for {issue['id']}: {slither_vulnerabilities_and_optimizations[issue['type']]['recommendation']}\"\n",
    "                comment = (tabs[i].get(\"tabs\")*\"\\t\") + comment1 + (tabs[i].get(\"tabs\")*\"\\t\") + comment2 + \"\\n\"\n",
    "\n",
    "        elif issue['construct'] == \"variable\" and issue['parent_construct'] == \"function\":\n",
    "            line_num = issue['parent_line'] - 1\n",
    "            if issue['severity'] == \"High\" or issue['severity'] == \"Medium\" or issue['severity'] == \"Low\":  \n",
    "\n",
    "                comment1 = f\"// WARNING Vulnerability ({issue['type']} | severity: {issue['severity']} | ID: {issue['id']}): {description}\"\n",
    "                comment2 = f\"// Recommendation for {issue['id']}: {slither_vulnerabilities_and_optimizations[issue['type']]['recommendation']}\"\n",
    "                comment = (tabs[i].get(\"tabs_parent\")*\"\\t\") + comment1 + (tabs[i].get(\"tabs_parent\")*\"\\t\") + comment2 + \"\\n\"                      \n",
    "\n",
    "            elif issue['severity'] == \"Optimization\":\n",
    "                comment1 = f\"// WARNING Optimization Issue ({issue['type']} | ID: {issue['id']}): {description}\"\n",
    "                comment2 = f\"// Recommendation for {issue['id']}: {slither_vulnerabilities_and_optimizations[issue['type']]['recommendation']}\"\n",
    "                comment = (tabs[i].get(\"tabs_parent\")*\"\\t\") + comment1 + (tabs[i].get(\"tabs_parent\")*\"\\t\") + comment2 + \"\\n\"\n",
    "\n",
    "        elif issue['construct'] == \"node\" or (issue['construct'] == \"variable\" and not issue['parent_construct'] == \"contract\"):\n",
    "            # type of issue (e.g. reentrancy-benign) | ID of corresponding issue\n",
    "            comment = (tabs[i].get(\"tabs\")*\"\\t\") + f\"// {issue['type']} | ID: {issue['id']}\" + \"\\n\"\n",
    "\n",
    "        # Inserts comment before the corresponding line\n",
    "        if 0 <= line_num < len(code_lines):\n",
    "            code_lines.insert(line_num, comment)        \n",
    "    \n",
    "    return code_lines\n",
    "\n",
    "# Analyses any contract and inserts vulnerability information\n",
    "def analyze_contract(contract_file):\n",
    "    try:\n",
    "        contract_path = os.path.join(unchecked_contracts_dir, contract_file)\n",
    "        output_json = f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Output_JSON/{contract_file}.json\"\n",
    "\n",
    "        # Carry out the slither analysis\n",
    "        # print(f\"Analyzing {contract_file}...\")\n",
    "\n",
    "        # Runs the slither analysis and captures the output as json file. Informational issues are excluded.\n",
    "        subprocess.run(\n",
    "            [\"slither\", contract_path, \"--exclude-informational\", \"--json\", output_json],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        # Reads and processes the JSON result\n",
    "        with open(output_json) as file:\n",
    "            data = json.load(file)       # the json file with the corresponding slither analysis result\n",
    "            issues = []                  # issues are annotated to the corresponding parent of the line where the vulnerability was found, i.e., to the function/contract which contains the statement or to the exact line\n",
    "            severities = []\n",
    "            if len(data.get(\"results\", {})) != 0:                                               # if slither results are empty no issues are available\n",
    "                for i in range(0, len(data.get(\"results\", {}).get(\"detectors\", []))):           # iterates over the existing detectors in slither json file\n",
    "                    issues += [\n",
    "                        {\n",
    "                            \"line\": element.get(\"source_mapping\", {}).get(\"lines\", [None])[0],                                                          # start line where vulnerability was found\n",
    "                            \"type\": data.get(\"results\", {}).get(\"detectors\", [])[i].get(\"check\", None),                                                 # type of vulnerability (i.e. the slither detector)\n",
    "                            \"severity\": data.get(\"results\", {}).get(\"detectors\", [])[i].get(\"impact\", None),                                            # severity of vulnerability\n",
    "                            \"description\": data.get(\"results\", {}).get(\"detectors\", [])[i].get(\"description\", None).replace(\"\\n\\t\", \" \").replace(\"-\", \"\").replace(\":\", \"\"),  # description of issue\n",
    "                            \"id\": data.get(\"results\", {}).get(\"detectors\", [])[i].get(\"id\", None)[-7:],                                                 # the id of a detected vulnerability\n",
    "                            \"construct\": element.get(\"type\", None),                                                                                     # the corresponding construct (contract/function/variable/node)\n",
    "                            \"parent_construct\": element.get(\"type_specific_fields\", {}).get(\"parent\", {}).get(\"type\", None),                            # the construcht of the parent\n",
    "                            \"parent_line\": element.get(\"type_specific_fields\", {}).get(\"parent\", {}).get(\"source_mapping\", {}).get(\"lines\", [0])[0],    # the start line of the parent\n",
    "                            \"parent_name\": element.get(\"type_specific_fields\", {}).get(\"parent\", {}).get(\"name\", None)                                  # name of the parent\n",
    "                        }\n",
    "                        for element in data.get(\"results\", {}).get(\"detectors\", [])[i].get(\"elements\", [])\n",
    "                    ] \n",
    "                issues = list({json.dumps(issue): issue for issue in issues}.values())        # deletes duplicates (i.e. identical issues) and keeps correct order. Uses json.dumps as dicts are mutable objects, \n",
    "                                                                                              # i.e., cannont be used as elements in sets. Therefore \"issues = list(dict.fromkeys(issues))\" does not work!\n",
    "                severities = [detector.get(\"impact\", None) for detector in data.get(\"results\", {}).get(\"detectors\", [])]   # a list of the severities of the corresponding vulnerabilities\n",
    "            \n",
    "        # Reads the original code\n",
    "        with open(contract_path, \"r\") as file:\n",
    "            code_lines = file.readlines()\n",
    "\n",
    "        annotated_code = code_lines\n",
    "        if issues:\n",
    "            annotated_code = insert_comments_with_position(code_lines, issues)  # Inserts vulnerability/optimization comments\n",
    "        \n",
    "        # Writes the commented code into an own new file and the corresponding folder (high/medium/low/optimization/secure)\n",
    "        if \"High\" in severities:\n",
    "            annotated_path = os.path.join(high_vulnerability_dir, contract_file)\n",
    "        elif \"Medium\" in severities:\n",
    "            annotated_path = os.path.join(medium_vulnerability_dir, contract_file)\n",
    "        elif \"Low\" in severities:\n",
    "            annotated_path = os.path.join(low_vulnerability_dir, contract_file)\n",
    "        elif \"Optimization\" in severities:\n",
    "            annotated_path = os.path.join(secure_contracts_dir, contract_file)\n",
    "        else:\n",
    "            annotated_path = os.path.join(secure_optimized_contracts_dir, contract_file)\n",
    "\n",
    "        with open(annotated_path, \"w\") as file:\n",
    "            file.writelines(annotated_code)\n",
    "                \n",
    "        os.remove(f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/DISL_Contract_Slither_Analysis/Output_JSON/{contract_file}.json\")        \n",
    "        # print(f\"Annotated contract saved to {annotated_path}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error analyzing {contract_file}: {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        # shutil.move(f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Test/{contract_file}\", secure_contracts_dir)\n",
    "        global count\n",
    "        count += 1\n",
    "        print(f\"Unexpected error with {contract_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def run_slither_parallel(path_r):\n",
    "    contract_files = os.listdir(path_r)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        executor.map(analyze_contract, contract_files)\n",
    "\n",
    "    print(\"Parallel Analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_slither_parallel(unchecked_contracts_dir)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of common contract imports\n",
    "contract_imports = {\n",
    "    # @openzeppelin/contracts/access/\n",
    "    \"AccessControl\": \"@openzeppelin/contracts/access/AccessControl.sol\",\n",
    "    \"IAccessControl\": \"@openzeppelin/contracts/access/IAccessControl.sol\",\n",
    "    \"Ownable\": \"@openzeppelin/contracts/access/Ownable.sol\",\n",
    "    \"Ownable2Step\": \"@openzeppelin/contracts/access/Ownable2Step.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/finance/\n",
    "    \"VestingWallet\": \"@openzeppelin/contracts/finance/VestingWallet.sol\",\n",
    "    \"VestingWalletCliff\": \"@openzeppelin/contracts/finance/VestingWalletCliff.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/governance/\n",
    "    \"Governor\": \"@openzeppelin/contracts/governance/Governor.sol\",\n",
    "    \"IGovernor\": \"@openzeppelin/contracts/governance/IGovernor.sol\",\n",
    "    \"TimelockController\": \"@openzeppelin/contracts/governance/TimelockController.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/interfaces/\n",
    "    \"IERC1155\": \"@openzeppelin/contracts/interfaces/IERC1155.sol\",\n",
    "    \"IERC1155MetadataURI\": \"@openzeppelin/contracts/interfaces/IERC1155MetadataURI.sol\",\n",
    "    \"IERC1155Receiver\": \"@openzeppelin/contracts/interfaces/IERC1155Receiver.sol\",\n",
    "    \"IERC1271\": \"@openzeppelin/contracts/interfaces/IERC1271.sol\",\n",
    "    \"IERC1363\": \"@openzeppelin/contracts/interfaces/IERC1363.sol\",\n",
    "    \"IERC1363Receiver\": \"@openzeppelin/contracts/interfaces/IERC1363Receiver.sol\",\n",
    "    \"IERC1363Spender\": \"@openzeppelin/contracts/interfaces/IERC1363Spender.sol\",\n",
    "    \"IERC165\": \"@openzeppelin/contracts/interfaces/IERC165.sol\",\n",
    "    \"IERC1820Implementer\": \"@openzeppelin/contracts/interfaces/IERC1820Implementer.sol\",\n",
    "    \"IERC1820Registry\": \"@openzeppelin/contracts/interfaces/IERC1820Registry.sol\",\n",
    "    \"IERC1967\": \"@openzeppelin/contracts/interfaces/IERC1967.sol\",\n",
    "    \"IERC20\": \"@openzeppelin/contracts/interfaces/IERC20.sol\",\n",
    "    \"IERC20Metadata\": \"@openzeppelin/contracts/interfaces/IERC20Metadata.sol\",\n",
    "    \"IERC20Errors\": \"@openzeppelin/contracts/interfaces/IERC20Errors.sol\",\n",
    "    \"IERC2309\": \"@openzeppelin/contracts/interfaces/IERC2309.sol\",\n",
    "    \"IERC2981\": \"@openzeppelin/contracts/interfaces/IERC2981.sol\",\n",
    "    \"IERC5805\": \"@openzeppelin/contracts/interfaces/IERC5805.sol\",\n",
    "    \"IERC721\": \"@openzeppelin/contracts/interfaces/IERC721.sol\",\n",
    "    \"IERC721Enumerable\": \"@openzeppelin/contracts/interfaces/IERC721Enumerable.sol\",\n",
    "    \"IERC721Metadata\": \"@openzeppelin/contracts/interfaces/IERC721Metadata.sol\",\n",
    "    \"IERC721Receiver\": \"@openzeppelin/contracts/interfaces/IERC721Receiver.sol\",\n",
    "    \"IERC777\": \"@openzeppelin/contracts/interfaces/IERC777.sol\",\n",
    "    \"IERC777Recipient\": \"@openzeppelin/contracts/interfaces/IERC777Recipient.sol\",\n",
    "    \"IERC777Sender\": \"@openzeppelin/contracts/interfaces/IERC777Sender.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/metatx/\n",
    "    \"ERC2771Context\": \"@openzeppelin/contracts/metatx/ERC2771Context.sol\",\n",
    "    \"ERC2771Forwarder\": \"@openzeppelin/contracts/metatx/ERC2771Forwarder.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/proxy/\n",
    "    \"Clones\": \"@openzeppelin/contracts/proxy/Clones.sol\",\n",
    "    \"Proxy\": \"@openzeppelin/contracts/proxy/Proxy.sol\",\n",
    "    \"BeaconProxy\": \"@openzeppelin/contracts/proxy/beacon/BeaconProxy.sol\",\n",
    "    \"IBeacon\": \"@openzeppelin/contracts/proxy/beacon/IBeacon.sol\",\n",
    "    \"Initializable\": \"@openzeppelin/contracts/proxy/utils/Initializable.sol\",\n",
    "    \"TransparentUpgradeableProxy\": \"@openzeppelin/contracts/proxy/transparent/TransparentUpgradeableProxy.sol\",\n",
    "    \"ProxyAdmin\": \"@openzeppelin/contracts/proxy/transparent/ProxyAdmin.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/token/\n",
    "    \"ERC1155\": \"@openzeppelin/contracts/token/ERC1155/ERC1155.sol\",\n",
    "    \"ERC1155Burnable\": \"@openzeppelin/contracts/token/ERC1155/extensions/ERC1155Burnable.sol\",\n",
    "    \"ERC1155Pausable\": \"@openzeppelin/contracts/token/ERC1155/extensions/ERC1155Pausable.sol\",\n",
    "    \"ERC1155Supply\": \"@openzeppelin/contracts/token/ERC1155/extensions/ERC1155Supply.sol\",\n",
    "    \"ERC20\": \"@openzeppelin/contracts/token/ERC20/ERC20.sol\",\n",
    "    \"ERC20Burnable\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Burnable.sol\",\n",
    "    \"ERC20Pausable\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Pausable.sol\",\n",
    "    \"ERC20Detailed\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Detailed.sol\", \n",
    "    \"ERC20Mintable\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Mintable.sol\",\n",
    "    \"ERC20Permit\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Permit.sol\",\n",
    "    \"ERC20Wrapper\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Wrapper.sol\",\n",
    "    \"ERC20FlashMint\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20FlashMint.sol\",\n",
    "    \"ERC20Capped\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Capped.sol\",\n",
    "    \"ERC1363\": \"@openzeppelin/contracts/token/ERC20/extensions/ERC1363.sol\",\n",
    "    \"SafeERC20\": \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\",\n",
    "    \"ERC721\": \"@openzeppelin/contracts/token/ERC721/ERC721.sol\",\n",
    "    \"ERC721Burnable\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Burnable.sol\",\n",
    "    \"ERC721Consecutive\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Consecutive.sol\",\n",
    "    \"ERC721Pausable\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Pausable.sol\",\n",
    "    \"ERC721Royalty\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Royalty.sol\",\n",
    "    \"ERC721Wrapper\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Wrapper.sol\",\n",
    "    \"ERC721Votes\": \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Votes.sol\",\n",
    "    \"ERC721Holder\": \"@openzeppelin/contracts/token/ERC721/utils/ERC721Holder.sol\",\n",
    "    \"ERC721Utils\": \"@openzeppelin/contracts/token/ERC721/utils/ERC721Utils.sol\",\n",
    "    \"ERC2981\": \"@openzeppelin/contracts/token/common/ERC2981.sol\",\n",
    "\n",
    "    # @openzeppelin/contracts/utils/\n",
    "    \"Address\": \"@openzeppelin/contracts/utils/Address.sol\",\n",
    "    \"Arrays\": \"@openzeppelin/contracts/utils/Arrays.sol\",\n",
    "    \"Bytes\": \"@openzeppelin/contracts/utils/Bytes.sol\",\n",
    "    \"Context\": \"@openzeppelin/contracts/utils/Context.sol\",\n",
    "    \"Panic\": \"@openzeppelin/contracts/utils/Panic.sol\",\n",
    "    \"Pausable\": \"@openzeppelin/contracts/utils/Pausable.sol\",\n",
    "    \"ReentrancyGuard\": \"@openzeppelin/contracts/utils/ReentrancyGuard.sol\",\n",
    "    \"ReentrancyGuardTransient\": \"@openzeppelin/contracts/utils/ReentrancyGuardTransient.sol\",\n",
    "    \"Strings\": \"@openzeppelin/contracts/utils/Strings.sol\",\n",
    "    \"Comparators\": \"@openzeppelin/contracts/utils/Comparators.sol\",\n",
    "    \"Counters\": \"@openzeppelin/contracts/utils/Counters.sol\",\n",
    "    \"Errors\": \"@openzeppelin/contracts/utils/Errors.sol\",\n",
    "    \"Nonces\": \"@openzeppelin/contracts/utils/Nonces.sol\",\n",
    "    \"Packing\": \"@openzeppelin/contracts/utils/Packing.sol\",\n",
    "    \"Time\": \"@openzeppelin/contracts/utils/types/Time.sol\",\n",
    "    \"Heap\": \"@openzeppelin/contracts/utils/structs/Heap.sol\",\n",
    "    \"MerkleTree\": \"@openzeppelin/contracts/utils/structs/MerkleTree.sol\",\n",
    "    \"BitMaps\": \"@openzeppelin/contracts/utils/structs/BitMaps.sol\",\n",
    "    \"Checkpoints\": \"@openzeppelin/contracts/utils/structs/Checkpoints.sol\",\n",
    "    \"EnumerableSet\": \"@openzeppelin/contracts/utils/structs/EnumerableSet.sol\",\n",
    "    \"EnumerableMap\": \"@openzeppelin/contracts/utils/structs/EnumerableMap.sol\",\n",
    "    \"Math\": \"@openzeppelin/contracts/utils/math/Math.sol\",\n",
    "    \"SafeMath\": \"@openzeppelin/contracts/utils/math/SafeMath.sol\",\n",
    "    \"SafeCast\": \"@openzeppelin/contracts/utils/math/SafeCast.sol\",\n",
    "    \"SignedMath\": \"@openzeppelin/contracts/utils/math/SignedMath.sol\",\n",
    "    \"ERC165\": \"@openzeppelin/contracts/utils/introspection/ERC165.sol\",\n",
    "    \"ECDSA\": \"@openzeppelin/contracts/utils/cryptography/ECDSA.sol\",\n",
    "    \"Hashes\": \"@openzeppelin/contracts/utils/cryptography/Hashes.sol\",\n",
    "    \"MerkleProof\": \"@openzeppelin/contracts/utils/cryptography/MerkleProof.sol\",\n",
    "    \"RSA\": \"@openzeppelin/contracts/utils/cryptography/RSA.sol\",\n",
    "    \"SignatureChecker\": \"@openzeppelin/contracts/utils/cryptography/SignatureChecker.sol\",\n",
    "\n",
    "    # Other openzeppelin contracts\n",
    "    \"ERC20PresetMinterPauser\": \"@openzeppelin/contracts/token/ERC20/presets/ERC20PresetMinterPauser.sol\",\n",
    "    \"ERC721PresetMinterPauserAutoId\": \"@openzeppelin/contracts/token/ERC721/presets/ERC721PresetMinterPauserAutoId.sol\",\n",
    "    \"VRFConsumerBase\": \"@openzeppelin/contracts/src/v0.8/VRFConsumerBase.sol\", \n",
    "    \"AggregatorV3Interface\": \"@openzeppelin/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol\", \n",
    "    \"PaymentSplitter\": \"@openzeppelin/contracts/finance/PaymentSplitter.sol\",\n",
    "\n",
    "    # Chainlink\n",
    "    \"VRFConsumerBase\": \"@chainlink/contracts/src/v0.8/VRFConsumerBase.sol\",\n",
    "    \"AggregatorV3Interface\": \"@chainlink/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol\", \n",
    "    \"LinkTokenInterface\": \"@chainlink/contracts/src/v0.8/interfaces/LinkTokenInterface.sol\",\n",
    "    \n",
    "    # Uniswap V2\n",
    "    \"IUniswapV2Router02\": \"@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router02.sol\",\n",
    "    \"IUniswapV2Router01\": \"@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router01.sol\",\n",
    "    \"IUniswapV2Factory\": \"@uniswap/v2-core/contracts/interfaces/IUniswapV2Factory.sol\",\n",
    "    \"IUniswapV2Pair\": \"@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol\",\n",
    "\n",
    "    # Uniswap V3\n",
    "    \"ISwapRouter\": \"@uniswap/v3-periphery/contracts/interfaces/ISwapRouter.sol\",\n",
    "    \"IQuoter\": \"@uniswap/v3-periphery/contracts/interfaces/IQuoter.sol\",\n",
    "    \"IUniswapV3Factory\": \"@uniswap/v3-core/contracts/interfaces/IUniswapV3Factory.sol\",\n",
    "    \"IUniswapV3Pool\": \"@uniswap/v3-core/contracts/interfaces/IUniswapV3Pool.sol\",\n",
    "\n",
    "    # Sushiswap (based on Uniswap V2)\n",
    "    \"ISushiRouter\": \"@sushiswap/core/contracts/uniswapv2/interfaces/IUniswapV2Router02.sol\",\n",
    "    \"ISushiFactory\": \"@sushiswap/core/contracts/uniswapv2/interfaces/IUniswapV2Factory.sol\",\n",
    "    \n",
    "    # Aave Protocol (v2 and v3)\n",
    "    \"ILendingPool\": \"@aave/protocol-v2/contracts/interfaces/ILendingPool.sol\",\n",
    "    \"IAToken\": \"@aave/protocol-v2/contracts/interfaces/IAToken.sol\",\n",
    "    \"IProtocolDataProvider\": \"@aave/protocol-v2/contracts/interfaces/IProtocolDataProvider.sol\",\n",
    "    \"ILendingPoolAddressesProvider\": \"@aave/protocol-v2/contracts/interfaces/ILendingPoolAddressesProvider.sol\",\n",
    "    \"IStableDebtToken\": \"@aave/protocol-v2/contracts/interfaces/IStableDebtToken.sol\",\n",
    "    \"IVariableDebtToken\": \"@aave/protocol-v2/contracts/interfaces/IVariableDebtToken.sol\",\n",
    "    \n",
    "    # Compound Protocol\n",
    "    \"CErc20\": \"@compound-finance/compound-protocol/contracts/CErc20.sol\",\n",
    "    \"Comptroller\": \"@compound-finance/compound-protocol/contracts/Comptroller.sol\",\n",
    "    \"PriceOracle\": \"@compound-finance/compound-protocol/contracts/PriceOracle.sol\",\n",
    "\n",
    "    # Balancer\n",
    "    \"IBalancerPool\": \"@balancer-labs/v2-pool-utils/contracts/interfaces/IBalancerPool.sol\",\n",
    "    \"IVault\": \"@balancer-labs/v2-vault/contracts/interfaces/IVault.sol\",\n",
    "    \n",
    "    # MakerDAO (DAI)\n",
    "    \"IDai\": \"@makerdao/dss/contracts/Dai.sol\",\n",
    "    \"IVat\": \"@makerdao/dss/contracts/Vat.sol\",\n",
    "    \"IJug\": \"@makerdao/dss/contracts/Jug.sol\",\n",
    "    \"IPot\": \"@makerdao/dss/contracts/Pot.sol\",\n",
    "    \n",
    "    # Curve Finance\n",
    "    \"ICurvePool\": \"@curvefi/contracts/contracts/pool/CurvePool.sol\",\n",
    "    \"ICurveFi\": \"@curvefi/contracts/contracts/ICurveFi.sol\",\n",
    "    \n",
    "    # Synthetix\n",
    "    \"ISynthetix\": \"@synthetixio/contracts/source/interfaces/ISynthetix.sol\",\n",
    "    \"IExchanger\": \"@synthetixio/contracts/source/interfaces/IExchanger.sol\",\n",
    "    \"IExchangeRates\": \"@synthetixio/contracts/source/interfaces/IExchangeRates.sol\",\n",
    "    \n",
    "    # Arbitrum (Layer 2 Solution)\n",
    "    \"IInbox\": \"@arbitrum/nitro/contracts/src/bridge/IInbox.sol\",\n",
    "    \"IOutbox\": \"@arbitrum/nitro/contracts/src/bridge/IOutbox.sol\",\n",
    "    \"IBridge\": \"@arbitrum/nitro/contracts/src/bridge/IBridge.sol\",\n",
    "\n",
    "    # Optimism (Layer 2 Solution)\n",
    "    \"L1CrossDomainMessenger\": \"@eth-optimism/contracts/L1/messaging/L1CrossDomainMessenger.sol\",\n",
    "    \"L2CrossDomainMessenger\": \"@eth-optimism/contracts/L2/messaging/L2CrossDomainMessenger.sol\",\n",
    "    \n",
    "    # ENS (Ethereum Name Service)\n",
    "    \"ENS\": \"@ensdomains/ens/contracts/ENS.sol\",\n",
    "    \"ENSRegistry\": \"@ensdomains/ens/contracts/ENSRegistry.sol\",\n",
    "    \"PublicResolver\": \"@ensdomains/resolver/contracts/PublicResolver.sol\",\n",
    "    \n",
    "    # Moloch DAO\n",
    "    \"IMoloch\": \"@molochventures/moloch/contracts/interfaces/IMoloch.sol\",\n",
    "    \n",
    "    # Gnosis Safe (Multisig)\n",
    "    \"GnosisSafe\": \"@gnosis.pm/safe-contracts/contracts/GnosisSafe.sol\",\n",
    "    \"GnosisSafeProxyFactory\": \"@gnosis.pm/safe-contracts/contracts/proxies/GnosisSafeProxyFactory.sol\",\n",
    "    \n",
    "    # Tornado Cash\n",
    "    \"ITornadoInstance\": \"@tornadocash/contracts/contracts/interfaces/ITornadoInstance.sol\",\n",
    "    \"ITornadoGovernance\": \"@tornadocash/contracts/contracts/interfaces/ITornadoGovernance.sol\",\n",
    "}\n",
    "\n",
    "def split_solidity_code(path_r, path_w):\n",
    "\n",
    "    with open(path_r, \"r\", encoding=\"utf-8\") as file:\n",
    "        source_code = file.read()\n",
    "\n",
    "    # Gets the length of the directory (this is necessary for the correct naming of the output files)\n",
    "    directory_length = len(os.listdir(path_w))\n",
    "\n",
    "    # Regex to match diverse definitions (contract, interface, abstract contract and so on)\n",
    "    pattern = re.compile(\n",
    "        r\"\\b(?:contract|interface|library|abstract\\s+contract)\\s+(\\w+)(?:\\s+is\\s+([^;{]+))?\\s*{\", \n",
    "        re.MULTILINE\n",
    "    )\n",
    "\n",
    "    # Finds all matches (each match corresponds to a new contract, interface, library, abstract contract or contract .. is ..)\n",
    "    matches = list(pattern.finditer(source_code))\n",
    "\n",
    "    # If no matches or only one contract in file do nothing\n",
    "    if not matches or len(matches) < 2:\n",
    "        # print(\"No contracts, interfaces, libraries, abstract contracts, or inheritance contracts found.\")\n",
    "        return\n",
    "\n",
    "    # Ensures that the output directory exists\n",
    "    if not os.path.exists(path_w):\n",
    "        os.makedirs(path_w)\n",
    "\n",
    "    # Gets the pragma solidity statement to carry it to each file\n",
    "    pragma_pattern = r\"pragma\\s+solidity\\s+[\\^<>=]*\\s*[0-9]+\\.[0-9]+\\.[0-9]+;\"\n",
    "    pragma_matches = re.findall(pragma_pattern, source_code, re.MULTILINE) \n",
    "\n",
    "    # Gets the spdx pattern to carry it to each file\n",
    "    spdx_pattern = r\"^// SPDX-License-Identifier: .*$\"\n",
    "    spdx_match = re.match(spdx_pattern, source_code, re.MULTILINE) \n",
    "\n",
    "    # The pattern for inheritance\n",
    "    contract_inheritance_pattern = r\"contract\\s+\\w+\\s+is\\s+([^;{]+)\"\n",
    "    interface_inheritance_pattern = r\"interface\\s+\\w+\\s+is\\s+([^;{]+)\"\n",
    "\n",
    "    # WARNING Vulnerability pattern, this is required to correctly split comments outside a contract with the contract\n",
    "    warning_vul_pattern = r\"// WARNING Vulnerability .*$\\n// Recommendation .*$\\ncontract\"\n",
    "\n",
    "    # A list of all contract/interface/library/abstract contract/... names which are in the current contract\n",
    "    contract_names = []\n",
    "    for match in matches:\n",
    "        contract_names.append(match.group(1))\n",
    "    \n",
    "    # This is required to place the extracted comment in the right contract file\n",
    "    count = -1\n",
    "    warning_vul_string = \"\"\n",
    "    # Splits the code into blocks and saves them in separate files\n",
    "    for i, match in enumerate(matches):\n",
    "        start_pos = match.start()  # Starting position of the current match\n",
    "        contract_type = re.sub(r' {', \"\", match.group(0))  # contract, interface, library, abstract contract, and so on ...\n",
    "        contract_name = match.group(1)  # The name of the contract/interface/library/abstract contract/...\n",
    "        contract_inherited = match.group(2)  # The name of the the inherited contracts\n",
    "\n",
    "        # Determines the end position: either the next match or the end of the file\n",
    "        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(source_code)\n",
    "\n",
    "        # Extracts the block of code for the current contract/interface/library\n",
    "        contract_code = source_code[start_pos:end_pos].strip()\n",
    "\n",
    "        # Detects commens before contracts and deletes this comment from the contract that is before this contract\n",
    "        comment_detection_code = source_code[start_pos:end_pos+8].strip()\n",
    "        warning_vul_matches = re.findall(warning_vul_pattern, comment_detection_code, re.MULTILINE)\n",
    "        if warning_vul_matches:\n",
    "            count = i + 1             # inserts it in next iteration\n",
    "            warning_vul_string = warning_vul_matches[0].replace(\"\\ncontract\", \"\")\n",
    "            contract_code = contract_code.replace(\"\\n\" + warning_vul_string, \"\")\n",
    "\n",
    "        # Deletes any comments (which are inserted during slither analysis) from the code. This is required for correct imports, as otherwise the dependency detection logic will detect wrong dependencies in comments\n",
    "        uncommented_code = re.sub(r\"//.*\", \"\", contract_code) \n",
    "\n",
    "        # Defines the imports for the corresponding contracts\n",
    "        imports = \"\"\n",
    "\n",
    "        # Searches for inheritances in the contract code besides these dependencies which are defined with \"is\"\n",
    "        tmp_code = re.sub(r\"\\b(?:contract|interface|library|abstract\\s+contract)\\s+(\\w+)(?:\\s+is\\s+([^;{]+))?\\s*{|\\\"(?:\\\\.|[^\\\"\\\\])*\\\"|\\'(?:\\\\.|[^\\'\\\\])*\\'\", \"\", uncommented_code)  # All ambiguities are removed from the code\n",
    "        tmp_list = []\n",
    "        for name in contract_names:\n",
    "            tmp_code2 = re.sub(rf\"(?<!\\w){name}(?![\\w,;])\", \"ThIsHaStObEuNiQuEaNdSoOn123\", tmp_code)     # Removes composed words which keep in the name (e.g. ERC20, ERC20.method should stay, but ERC20Example, ERC20SeeHere00 should not stay)\n",
    "            if \"ThIsHaStObEuNiQuEaNdSoOn123\" in tmp_code2 and name in tmp_code:\n",
    "                tmp_list.append(name)\n",
    "\n",
    "        # Searches for inheritances in the contract code which are defined with keywords like \"using\" or \"is\" and creates the corresponding imports\n",
    "        inheritance_matches = re.findall(contract_inheritance_pattern, uncommented_code, re.MULTILINE)     # Finds all \"(abstract) contract ... is ...\" dependencies\n",
    "        inheritance_matches += re.findall(interface_inheritance_pattern, uncommented_code, re.MULTILINE)   # Finds all \"interface ... is ...\" dependencies\n",
    "        if inheritance_matches or tmp_list:\n",
    "            contracts = []\n",
    "            if inheritance_matches:                                                                     # \"Is\" dependencies are collected\n",
    "                contracts += [contract.strip() for contract in inheritance_matches[0].split(',')]\n",
    "            contracts += tmp_list                                                                       # The list with all other dependencies is added\n",
    "            contracts = list(dict.fromkeys(contracts))                                                  # Deletes duplicates but keeps the correct order\n",
    "            for j in range(len(contracts)):\n",
    "                if contracts[j] in contract_imports.keys():\n",
    "                    imports += f'import \"{contract_imports[contracts[j]]}\" as {contracts[j]};\\n'                          # Imports the required dependency from Github\n",
    "                else:\n",
    "                    imports += f'import \"./{contracts[j]}.sol\" as {contracts[j]};\\n'                                      # Imports the required dependency as local file\n",
    "\n",
    "        # Combines the spdx identifier, pragma, and imports with the contract code\n",
    "        full_code = \"\"\n",
    "        if imports == \"\":\n",
    "            if count == i:        # inserts warning_vul_string in next iteration\n",
    "                full_code = f\"{spdx_match.group(0)}\\n\\n{pragma_matches[0]}\\n{imports}\\n{warning_vul_string}\\n{contract_code}\"\n",
    "            else:\n",
    "                full_code = f\"{spdx_match.group(0)}\\n\\n{pragma_matches[0]}\\n{imports}\\n{contract_code}\"\n",
    "        else:\n",
    "            if count == i:\n",
    "                full_code = f\"{spdx_match.group(0)}\\n\\n{pragma_matches[0]}\\n\\n{imports}\\n{warning_vul_string}\\n{contract_code}\"\n",
    "            else:\n",
    "                full_code = f\"{spdx_match.group(0)}\\n\\n{pragma_matches[0]}\\n\\n{imports}\\n{contract_code}\"\n",
    "\n",
    "        # Writes each block to a separate file\n",
    "        output_file = os.path.join(path_w, f\"solidity_code_{1+i+directory_length}.sol\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_code)\n",
    "            # print(f\"Saved '{contract_type}' to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Mixed_Dataset\"\n",
    "\n",
    "solidity_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "\n",
    "for file in solidity_files:\n",
    "    split_solidity_code(f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Mixed_Dataset/{file}\",\n",
    "                        f\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Splitted_Dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Jaccard Similarity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Jaccard similarity of two sets. The Jaccard similarity is defined as the intersection of two sets divided by the union of these sets.\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Removes similar contracts according to a threshold.\n",
    "def remove_similar_contracts(input_dir, output_dir, threshold=0.9):\n",
    "\n",
    "    tokenized_contracts = []\n",
    "    original_contracts = []\n",
    "    # Keeps track of the duplicates\n",
    "    duplicates = set()\n",
    "\n",
    "    # Reads each contract and tokenizes it\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".sol\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                contract = file.read()\n",
    "                # contract_for_tokenization = re.sub(r\"//.*\", \"\", contract)       # comments are removed for similarity check, as they might falsify the result\n",
    "                tokens = set(re.findall(r'\\w+', contract))\n",
    "                tokenized_contracts.append(tokens)\n",
    "                original_contracts.append(contract)\n",
    "\n",
    "    # Compares the contracts for similarity with Jaccard similarity\n",
    "    for i in range(len(tokenized_contracts)):\n",
    "        for j in range(i + 1, len(tokenized_contracts)):\n",
    "            similarity = jaccard_similarity(tokenized_contracts[i], tokenized_contracts[j])\n",
    "            if similarity > threshold:\n",
    "                duplicates.add(j)\n",
    "\n",
    "    # Writes unique contracts to the output directory\n",
    "    k = 0\n",
    "    for i in range(len(tokenized_contracts)):\n",
    "        if i not in duplicates:\n",
    "            k += 1\n",
    "            output_file_path = os.path.join(output_dir, f\"solidity_code_{k}.sol\")\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(original_contracts[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_similar_contracts(\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/SpecialToken_Dataset/\", \n",
    "                         \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Fill_in_the_Middle/\", \n",
    "                         0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Solhint fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset\"\n",
    "\n",
    "# Fixes some of the Solhint warnings. (avoid-throw, avoid-sha3, no-console, explicit-types, private-vars-underscore, payable-fallback, quotes, contract-name-camelcase, avoid-suicide)\n",
    "def solhint_fixes(file_name):\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"C:/Users/Fabian Hensel/AppData/Roaming/npm/solhint.cmd\", \"--fix\", \"--noPrompt\", file_name],\n",
    "            check=True,\n",
    "            cwd=folder_path\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying fixes to {file_name}: {e}\")\n",
    "\n",
    "def run_solhint_parallel(path_r):\n",
    "    contract_files = os.listdir(path_r)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        executor.map(solhint_fixes, contract_files)\n",
    "\n",
    "    print(\"Parallel fixing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_solhint_parallel(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Special Token Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Inserts special tokens such as [begin_function] [end_function] to mark specific regions in the code. This should help the llm during fine-tuning to recognize specific patterns. \n",
    "def insert_special_tokens(path_r, path_w, constructList):\n",
    "\n",
    "    try:\n",
    "        with open(path_r, \"r\", encoding='utf-8') as file:   \n",
    "            solidity_code = file.read()\n",
    "\n",
    "        # Removes shadowing-local vulnerability annotations, as these are irrelevant for function extraction\n",
    "        # shadowing_local_pattern = r\"\\/\\/ WARNING Vulnerability \\(shadowing-local.*\\n\\t\\/\\/ Recommendation for.*\"\n",
    "        # solidity_code = re.sub(shadowing_local_pattern, '', solidity_code)\n",
    "        # solidity_code = re.sub('\\n\\n\\t\\n', '\\n\\n', solidity_code)\n",
    "\n",
    "        # For vulnerability detection in constructs such as contracts, interfaces, and libraries\n",
    "        vul_pattern = r\"// WARNING Vulnerability\"\n",
    "        vul_matches = len(re.findall(vul_pattern, solidity_code))\n",
    "\n",
    "        for construct in constructList:\n",
    "\n",
    "            modified_code = []\n",
    "            last_end = 0 \n",
    "            functions_code = []\n",
    "\n",
    "            pattern = \"\"\n",
    "            begin_token = \"\"\n",
    "            end_token = \"\"\n",
    "\n",
    "            start_pattern = r\"// SPDX-License-Identifier: [^{}]*\\{\"\n",
    "            start_match = 0\n",
    "            for match in re.finditer(start_pattern, solidity_code):\n",
    "                start_match = match\n",
    "\n",
    "            if construct == \"function\":\n",
    "                pattern = r\"    function [^{};]*(\\{|\\;)\"                 # Matches the function header until { or ; The indentation is on purpose to avoid to match with wrong function words (e.g. in comments) \n",
    "                # begin_token = \"\\t<|secure_function|>\\n\"\n",
    "                end_token = \"[END_FUN]\"\n",
    "                begin_vulnerable_token = \"<|vulnerable_function|>\\n\"\n",
    "                end_vulnerable_token = \"[END_VUL_FUN]\"\n",
    "                functions_code = extract_constructs(solidity_code)[0]\n",
    "\n",
    "            elif construct == \"contract\":\n",
    "                pattern = r\"(?m)^(abstract|contract) [^{}]*\\{\"               # Matches the contract header until {   \n",
    "                if vul_matches > 0:              \n",
    "                    begin_token = \"[BEG_VUL_CON]\\n\"\n",
    "                    end_token = \"[END_VUL_CON]\"\n",
    "                else:\n",
    "                    #begin_token = \"[BEG_CON]\\n\"\n",
    "                    end_token = \"[END_CON]\"\n",
    "\n",
    "            elif construct == \"interface\":\n",
    "                pattern = r\"interface [^{}]*\\{\"                         # Matches the interface header until {\n",
    "                if vul_matches > 0:\n",
    "                    begin_token = \"[BEG_VUL_INT]\\n\"\n",
    "                    end_token = \"[END_VUL_INT]\"\n",
    "                else:\n",
    "                    #begin_token = \"[BEG_INT]\\n\"\n",
    "                    end_token = \"[END_INT]\"\n",
    "\n",
    "            elif construct == \"constructor\":\n",
    "                pattern = r\"    constructor[^{}]*\\{\"                    # Matches the constructor header until {\n",
    "                #begin_token = \"\\t[BEG_CSR]\\n\"\n",
    "                end_token = \"[END_CSR]\"\n",
    "                begin_vulnerable_token = \"<|vulnerable_constructor|>\\n\"\n",
    "                end_vulnerable_token = \"[END_VUL_CSR]\"\n",
    "                constructors_code = extract_constructs(solidity_code)[3]\n",
    "\n",
    "            elif construct == \"struct\":\n",
    "                pattern = r\"    struct[^{}]*\\{\"                         # Matches the struct header until {\n",
    "                #begin_token = \"\\t[BEG_STR]\\n\"\n",
    "                end_token = \"[END_STR]\"\n",
    "\n",
    "            elif construct == \"modifier\":\n",
    "                pattern = r\"    modifier [^{};]*(\\{|\\;)\"                 # Matches the modifier header until {    \n",
    "                #begin_token = \"\\t[BEG_MOD]\\n\"\n",
    "                end_token = \"[END_MOD]\"\n",
    "\n",
    "            elif construct == \"event\":                  \n",
    "                pattern = r\"    event [^{};]*\\;\"                          # Matches the event until ;\n",
    "                #begin_token = \"\\t[BEG_EVE]\\n\"\n",
    "                end_token = \"[END_EVE]\"\n",
    "\n",
    "            elif construct == \"enum\":\n",
    "                pattern = r\"    enum [^{}]*\\{\"                          # Matches the enum until }\n",
    "                #begin_token = \"\\t[BEG_ENU]\\n\"\n",
    "                end_token = \"[END_ENU]\"\n",
    "\n",
    "            elif construct == \"error\":\n",
    "                pattern = r\"    error [^{};]*\\;\"                        # Matches an error until ;\n",
    "                #begin_token = \"\\t[BEG_ERR]\\n\"\n",
    "                end_token = \"[END_ERR]\"\n",
    "\n",
    "            elif construct == \"library\":\n",
    "                pattern = r\"library [^{}]*\\{\"                           # Matches the library header until {\n",
    "                if vul_matches > 0:\n",
    "                    begin_token = \"[BEG_VUL_LIB]\\n\"\n",
    "                    end_token = \"[END_VUL_LIB]\"\n",
    "                else:\n",
    "                    #begin_token = \"[BEG_LIB]\\n\"\n",
    "                    end_token = \"[END_LIB]\"\n",
    "\n",
    "            elif construct == \"assembly\": \n",
    "                pattern = r\"assembly [^{}]*\\{\"                          # Matches the library header until { ; Here also the spaces are counted as assembly could have a different number of spaces\n",
    "                #begin_token = f\"[BEG_ASM]\"\n",
    "                end_token = f\"[END_ASM]\"\n",
    "                begin_vulnerable_token = f\"[BEG_VUL_ASM]\"\n",
    "                end_vulnerable_token = f\"[END_VUL_ASM]\"\n",
    "                assemblies_code = extract_constructs(solidity_code)[2]\n",
    "\n",
    "            elif construct == \"mapping\":\n",
    "                pattern = r\"    mapping[^{};]*\\;\"                      # Matches the mapping until ;\n",
    "                # begin_token = f\"[BEG_MAP]\"\n",
    "                end_token = f\"[END_MAP]\"\n",
    "\n",
    "            else:\n",
    "                print(\"No valid construct.\")\n",
    "                return\n",
    "\n",
    "            lines = solidity_code.split(\"\\n\")\n",
    "\n",
    "            # Iterates over all construct matches\n",
    "            for i, (match, match2) in enumerate(zip(re.finditer(pattern, solidity_code), re.findall(pattern, solidity_code))):\n",
    "                # Adds the code before the function to the output\n",
    "                modified_code.append(solidity_code[last_end:match.start()])\n",
    "\n",
    "                match_lines = solidity_code[last_end-1:match.start()].split(\"\\n\")\n",
    "                final_match = \"\"\n",
    "\n",
    "                start_match_lines = solidity_code[start_match.end():match.start()].split(\"\\n\")\n",
    "                final_start_match = \"\"\n",
    "\n",
    "                try:\n",
    "                    if i == 0:\n",
    "                        final_start_match = start_match_lines[-3]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    final_match = match_lines[-3]\n",
    "                    if i == 0:\n",
    "                        final_start_match = start_match_lines[-3]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                start_index = match.end() - 1                                   # position of the '{' that starts the construct body\n",
    "                end_index = start_index + 1                                     # position of the '}' that ends the construct body\n",
    "\n",
    "                # For vulnerability detection in constructs such as functions, assemblies, and constructors \n",
    "                vul_hit = False\n",
    "                vul_pattern_2 = r\"//.* | ID:\"\n",
    "\n",
    "                if (\"{\" in match2 or \"contract\" in match2 or \"struct\" in match2 or \"library\" in match2 or \"interface\" in match2 or \"constructor\" in match2 or \"abstract\" in match2 or \"enum\" in match2) and not \"->\" in str(match):\n",
    "\n",
    "                    if \"function\" in str(match):\n",
    "                        function_code = functions_code[i]\n",
    "                        if re.search(vul_pattern_2, function_code) or re.search(vul_pattern, final_match) or (re.search(vul_pattern, final_start_match) and i == 0):\n",
    "                            vul_hit = True\n",
    "\n",
    "                    if \"constructor\" in str(match):\n",
    "                        constructor_code = constructors_code[i]\n",
    "                        if re.search(vul_pattern_2, constructor_code) or re.search(vul_pattern, final_match) or (re.search(vul_pattern, solidity_code[start_match.end():match.start()]) and i == 0):\n",
    "                            vul_hit = True\n",
    "\n",
    "                    if \"assembly\" in str(match):\n",
    "                        assembly_code = assemblies_code[i]\n",
    "                        spaces = 0\n",
    "                        if re.search(vul_pattern_2, assembly_code):\n",
    "                            vul_hit = True\n",
    "\n",
    "                        for line in lines:\n",
    "                            if \"assembly\" in line:\n",
    "                                spaces = len(line) - len(line.lstrip(' '))\n",
    "                                lines.remove(line)\n",
    "                                break\n",
    "                        \n",
    "                        if not vul_hit:\n",
    "                            modified_code.append(begin_token+\"\\n\"+spaces*' ')\n",
    "                        else:\n",
    "                            modified_code.append(begin_vulnerable_token+\"\\n\"+spaces*' ')\n",
    "                    else: \n",
    "                        # Adds the [begin_construct] token before the construct if no vulnerability was detected, otherwise the [begin_vulnerable_construct] is added\n",
    "                        if not vul_hit:\n",
    "                            modified_code.append(begin_token)\n",
    "                        else:\n",
    "                            modified_code.append(begin_vulnerable_token)\n",
    "            \n",
    "                    brace_count = 1            # initializes the brace count\n",
    "\n",
    "                    # Finds the closing brace of the construct\n",
    "                    while brace_count > 0 and end_index < len(solidity_code):\n",
    "                        if solidity_code[end_index] == '{':\n",
    "                            brace_count += 1\n",
    "                        elif solidity_code[end_index] == '}':\n",
    "                            brace_count -= 1\n",
    "                        end_index += 1\n",
    "                    \n",
    "                    # Adds the construct code along with the [end_construct] token\n",
    "                    modified_code.append(solidity_code[match.start():end_index])\n",
    "\n",
    "                    # if not vul_hit:\n",
    "                    #     modified_code.append(end_token)\n",
    "                    # else:\n",
    "                    #     modified_code.append(end_vulnerable_token)\n",
    "\n",
    "                elif \"->\" in str(match):\n",
    "                    continue\n",
    "                else:\n",
    "                    if \"function\" in str(match):\n",
    "                        function_code = functions_code[i]\n",
    "                        if (re.search(vul_pattern, final_start_match) and i == 0):\n",
    "                            modified_code.append(begin_vulnerable_token)\n",
    "                            modified_code.append(solidity_code[match.start():end_index])\n",
    "                            #modified_code.append(end_vulnerable_token+\"\\n\")\n",
    "                        else:\n",
    "                            # modified_code.append(begin_token)\n",
    "                            modified_code.append(solidity_code[match.start():end_index])\n",
    "                            #modified_code.append(end_token+\"\\n\")\n",
    "                    else:\n",
    "                        # modified_code.append(begin_token)\n",
    "                        modified_code.append(solidity_code[match.start():end_index])\n",
    "                        #modified_code.append(end_token+\"\\n\")\n",
    "                    end_index += 1\n",
    "\n",
    "                # Updates last_end to continue parsing after this construct\n",
    "                last_end = end_index\n",
    "\n",
    "            # Adds any remaining code after the last construct\n",
    "            modified_code.append(solidity_code[last_end:])\n",
    "\n",
    "            solidity_code = ''.join(modified_code)\n",
    "\n",
    "        with open(path_w, \"w\", encoding='utf-8') as file:\n",
    "            file.write(solidity_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Extracts the code of all functions, modifiers, assemblies, and constructors of a solidity file and puts it into a list\n",
    "def extract_constructs(solidity_code):\n",
    "\n",
    "    function_pattern = r\"    function [^{};]*(\\{|\\;)\"\n",
    "    modifier_pattern = r\"    modifier [^{};]*(\\{|\\;)\"\n",
    "    assembly_pattern = r\"assembly [^{}]*\\{\"\n",
    "    constructor_pattern = r\"    constructor[^{}]*\\{\"\n",
    "\n",
    "    patterns = [function_pattern, modifier_pattern, assembly_pattern, constructor_pattern]\n",
    "\n",
    "    constructs_code = []\n",
    "    functions_code = []\n",
    "    modifiers_code = []\n",
    "    assemblies_code = []\n",
    "    constructors_code = []\n",
    "\n",
    "    # Iterates over the given patterns\n",
    "    for pattern in patterns:\n",
    "\n",
    "        # Iterates over the construct matches\n",
    "        for match in re.finditer(pattern, solidity_code):\n",
    "            start_index = match.end() - 1                                   \n",
    "            end_index = start_index + 1\n",
    "\n",
    "            brace_count = 0\n",
    "            for index in range(start_index, len(solidity_code)):\n",
    "                if solidity_code[index] == \"{\":\n",
    "                    brace_count += 1\n",
    "                elif solidity_code[index] == \"}\":\n",
    "                    brace_count -= 1\n",
    "                    \n",
    "                if brace_count == 0:\n",
    "                    end_index = index\n",
    "                    break\n",
    "            \n",
    "            if pattern == function_pattern:\n",
    "                functions_code.append(solidity_code[match.start():end_index+1])\n",
    "            elif pattern == modifier_pattern:\n",
    "                modifiers_code.append(solidity_code[match.start():end_index+1])\n",
    "            elif pattern == assembly_pattern:\n",
    "                assemblies_code.append(solidity_code[match.start():end_index+1])\n",
    "            elif pattern == constructor_pattern:\n",
    "                constructors_code.append(solidity_code[match.start():end_index+1])\n",
    "\n",
    "    constructs_code.append(functions_code)\n",
    "    constructs_code.append(modifiers_code)\n",
    "    constructs_code.append(assemblies_code)\n",
    "    constructs_code.append(constructors_code)\n",
    "\n",
    "    return constructs_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset\"\n",
    "\n",
    "solidity_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "\n",
    "for file in solidity_files:\n",
    "    insert_special_tokens(path_r=f\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset/{file}\",\n",
    "                          path_w=f\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/SpecialToken_Dataset/{file}\",\n",
    "                          constructList=[\"function\", \"contract\", \"interface\", \"constructor\", \"struct\", \"modifier\", \"library\", \"assembly\", \"event\", \"enum\", \"error\", \"mapping\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Step: Construct Extraction, FIM Transformation (Token Insertion), Single-line Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import groupby\n",
    "\n",
    "# Extracts the code of the diverse solidity constructs \n",
    "def extract_constructs(path_r, path_w):\n",
    "\n",
    "    with open(path_r, \"r\", encoding=\"utf-8\") as file:\n",
    "        solidity_code = file.read()\n",
    "\n",
    "    # The patterns to search for inside the code\n",
    "    function_pattern = r\"    function [^{};]*(\\{|\\;)\"\n",
    "    modifier_pattern = r\"    modifier [^{};]*(\\{|\\;)\"\n",
    "    mapping_pattern = r\"    mapping[^{};]*\\;\"\n",
    "    struct_pattern = r\"    struct[^{}]*\\{\"\n",
    "    error_pattern = r\"    error [^{};]*\\;\"\n",
    "    enum_pattern = r\"    enum [^{}]*\\{\"\n",
    "    event_pattern = r\"    event [^{};]*\\;\"\n",
    "    import_pattern = r\"import [^{};]*\\;\"\n",
    "    spdx_pattern = r\"// SPDX-License-Identifier: .*\"\n",
    "    using_pattern = r\"    using [^{};]*\\;\"\n",
    "    constructor_pattern = r\"    constructor[^{}]*\\{\"\n",
    "    pragma_pattern = r\"pragma [^{}]*\\{\"\n",
    "    # statement_pattern = r\"    (string|uint256|int256|bool|address|bytes).*? = [^{}();]*?;\"\n",
    "    \n",
    "    patterns = [function_pattern, \n",
    "                modifier_pattern, \n",
    "                mapping_pattern, \n",
    "                struct_pattern, \n",
    "                error_pattern, \n",
    "                enum_pattern, \n",
    "                event_pattern, \n",
    "                import_pattern, \n",
    "                spdx_pattern, \n",
    "                using_pattern,\n",
    "                constructor_pattern,\n",
    "                pragma_pattern]\n",
    "\n",
    "    # To numerate the sol_files correct\n",
    "    directory_length = len(os.listdir(path_w))\n",
    "    i = 1\n",
    "\n",
    "    # Iterates over the given patterns\n",
    "    for pattern in patterns:\n",
    "\n",
    "        # Iterates over the construct matches\n",
    "        for match in re.finditer(pattern, solidity_code):\n",
    "            start_index = match.end() - 1                                   \n",
    "            end_index = start_index + 1\n",
    "\n",
    "            # Identifies where a construct such as a function ends with help of the brackets\n",
    "            brace_count = 0\n",
    "            for index in range(start_index, len(solidity_code)):\n",
    "                if solidity_code[index] == \"{\":\n",
    "                    brace_count += 1\n",
    "                elif solidity_code[index] == \"}\":\n",
    "                    brace_count -= 1\n",
    "                    \n",
    "                if brace_count == 0:\n",
    "                    end_index = index\n",
    "                    break\n",
    "            \n",
    "            if pattern == function_pattern:\n",
    "                function_header = solidity_code[match.start():match.end()]         # function header gets extracted\n",
    "                function_body = solidity_code[match.end():end_index+1]             # function body gets extracted\n",
    "                code = create_fim_samples(function_header, function_body, '<|secure_function|>\\n', '<|vulnerable_function|>\\n', upper_token_limit=35)       # fim is applied\n",
    "\n",
    "            elif pattern == modifier_pattern:\n",
    "                modifier_header = solidity_code[match.start():match.end()]\n",
    "                modifier_body = solidity_code[match.end():end_index+1]\n",
    "                code = create_fim_samples(modifier_header, modifier_body, '', '', upper_token_limit=25)\n",
    "\n",
    "            elif pattern == constructor_pattern: \n",
    "                constructor_header = solidity_code[match.start():match.end()]\n",
    "                constructor_body = solidity_code[match.end():end_index+1]\n",
    "                code = create_fim_samples(constructor_header, constructor_body, '<|secure_constructor|>\\n', '<|vulnerable_constructor|>\\n', upper_token_limit=25)\n",
    "\n",
    "            elif pattern == pragma_pattern: \n",
    "                if re.search(import_pattern, solidity_code):\n",
    "                    pragma_body = solidity_code[match.start():match.end()]\n",
    "                    contract_vul_pattern = r\"\\/\\/ WARNING Vulnerability.*\\n\\/\\/ Recommendation for.*\"\n",
    "                    unclear_dependency_pattern = r\"\\(.*\\)\"                                                         # to not count wrong commas in dependency definitions such as ERC721(\"Friendly Fractals N\", \"FRFRACN\")\n",
    "                    pragma_body = re.sub(contract_vul_pattern, '', pragma_body)                                    # removes the vulnerability (if there) annotations for contracts (not required here)\n",
    "                    pragma_body = re.sub('\\n\\n\\n', '\\n\\n', pragma_body)\n",
    "                    lines = pragma_body.strip().split('\\n')\n",
    "                    flatten = pragma_body.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()  # flattens the contract definition to one line, to also detect commas in multiline definitions\n",
    "                    flatten = re.sub(unclear_dependency_pattern, '', flatten)\n",
    "                    comma_count = flatten.count(',')                                                               # counts the commas in the contracts defintion to detect the dependencies\n",
    "                    mid_start = 2                                                                                  # mid start is alway 2 as the format is clear \n",
    "                    all_imports_end = max_consecutive_count(lines, import_pattern) + mid_start                     # all_imports is mid start + all consecutive counted imports\n",
    "                    mid_end = comma_count + 1 + mid_start                                                          # mid end is mid start plus the comma_counts of the dependencies in the contract definition + 1\n",
    "                    useless_lines = lines[mid_end:all_imports_end]\n",
    "                    for line in useless_lines:                                                                     # the useless lines are removed\n",
    "                        lines.remove(line)\n",
    "                    prefix = '\\n'.join(lines[:mid_start])\n",
    "                    middle = '\\n'.join(lines[mid_start:mid_end])\n",
    "                    suffix = '\\n'.join(lines[mid_end:])\n",
    "\n",
    "                    code = '<|fim_begin|>' + prefix + '\\n' + '<|fim_hole|>' + '\\n' + suffix + '<|fim_end|>' + middle\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                code = solidity_code[match.start():end_index+1]\n",
    "\n",
    "            code = code.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()\n",
    "            output_file = os.path.join(path_w, f\"solidity_code_{i+directory_length}.sol\")\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(code)\n",
    "            i += 1\n",
    "\n",
    "# This function is only required for the fim realization of the imports. It counts how much imports are between the pragma and the begin of the contract.\n",
    "def max_consecutive_count(no_lines, import_pattern):\n",
    "    max_count = 0\n",
    "    current_count = 0\n",
    "\n",
    "    for item in no_lines:\n",
    "        if re.search(import_pattern, item):\n",
    "            current_count += 1\n",
    "            max_count = max(max_count, current_count)\n",
    "        else:\n",
    "            current_count = 0  # resets the count when a different element appears\n",
    "\n",
    "    return max_count\n",
    "\n",
    "# Realizes fill in the middle for functions, i.e. the function is splitted into prefix, middle, and suffix and the middle part is moved to the end. Additionally, fim tokens are inserted.\n",
    "def create_fim_samples(header, body, secure_token, vulnerable_token, upper_token_limit=35, fim_ratio=0.4):\n",
    "\n",
    "    body = re.sub(r' \\| ID:.*', ' vulnerability', body)      # replaces the inner construct vulnerability pattern by 'vul-type vulnerability'\n",
    "\n",
    "    lines = body.strip().split('\\n')              # splits the functions body into single lines\n",
    "    lines[0] = '\\n        ' + lines[0]            # adds to the first line the corresponding newline and spaces, as these are otherwise removed\n",
    "    lines = [x for x, _ in groupby(lines)]        # removes consecutive duplicates, i.e. for a list = ['a', 'a', 'b', 'a', 'a'] to list = ['a', 'b', 'a']\n",
    "\n",
    "    unchanged_lines = lines                       # for the case of to short or to long functions, the blank lines '' should not be removed, i.e. the body stays unchanged\n",
    "\n",
    "    inner_vul_pattern = r\".*\\/\\/.*|.*\"               # the pattern to search for inside functions or constructors to verify them as vulnerable. Pattern was inserted during slither analysis step\n",
    "\n",
    "    with_fim = \"\"\n",
    "    without_fim = \"\"\n",
    "\n",
    "    removed_indices = [i for i, x in enumerate(lines) if x == '']                # tracks the indices of the ''\n",
    "    lines = list(filter(lambda x: x != '', lines))                               # removes blank lines as the fim_hole token should not be used for an empty line\n",
    "\n",
    "    # Restores the indices after fim is applied, such that the format stays correct\n",
    "    def restore_indices(sublist, sublist_start_idx):\n",
    "        for index in removed_indices:\n",
    "            if sublist_start_idx <= index < sublist_start_idx + len(sublist):\n",
    "                sublist.insert(index - sublist_start_idx, '')                    # inserts '' at the right indices\n",
    "        return sublist\n",
    "\n",
    "    if len(lines) < 3 or len(lines) > upper_token_limit:                         # very short and very long functions will be ignored\n",
    "        unchanged_body = '\\n'.join(unchanged_lines[:])\n",
    "        if re.search(inner_vul_pattern, body):\n",
    "            without_fim = vulnerable_token + header + unchanged_body\n",
    "        else:\n",
    "            without_fim = secure_token + header + unchanged_body\n",
    "        # without_fim = without_fim.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()     # converts the function to one line\n",
    "        return without_fim\n",
    "\n",
    "    mid_start = random.randint(0, len(lines) - 3)                                          # defines randomly the start point of the middle part, e.g. lines == 5 than start point between 0 and (inclusive) 2\n",
    "    mid_end = min(mid_start + max(1, int(len(lines) * fim_ratio)), len(lines) - 1)         # determines the end point of the middle part, fim_ratio defines how much lines approximately are moved out\n",
    "\n",
    "    prefix = '\\n'.join(restore_indices(lines[:mid_start], 0))\n",
    "    middle = '\\n'.join(restore_indices(lines[mid_start:mid_end], mid_start))\n",
    "    suffix = '\\n'.join(restore_indices(lines[mid_end:], mid_end))\n",
    "\n",
    "    # Searches for the vulnerability pattern and applies corresponding tokens\n",
    "    if re.search(inner_vul_pattern, body):\n",
    "        with_fim = vulnerable_token + '<|fim_begin|>' + header + prefix + '\\n' + '<|fim_hole|>' + '\\n' + suffix + '<|fim_end|>' + middle\n",
    "    else:\n",
    "        with_fim = secure_token + '<|fim_begin|>' + header + prefix + '\\n' + '<|fim_hole|>' + '\\n' + suffix + '<|fim_end|>' + middle\n",
    "\n",
    "    # with_fim = with_fim.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()\n",
    "    return with_fim\n",
    "\n",
    "    # code = code.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset\"\n",
    "\n",
    "solidity_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "\n",
    "for file in solidity_files:\n",
    "    extract_constructs(path_r=f\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Solhint_Dataset/{file}\",\n",
    "                       path_w=f\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/SpecialToken_Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions during Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Fill_in_the_Middle/Test\"\n",
    "\n",
    "base_name = \"solidity_code_\"\n",
    "file_extension = \".sol\"\n",
    "\n",
    "# Gets a sorted list of all .sol files in the directory\n",
    "files = sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension)])\n",
    "\n",
    "# Loops through each file and rename it\n",
    "for index, filename in enumerate(files, start=1):\n",
    "    # Constructs the new file name\n",
    "    new_name = f\"{base_name}{index}{file_extension}\"\n",
    "    \n",
    "    # Defines the full file paths\n",
    "    old_file = os.path.join(folder_path, filename)\n",
    "    new_file = os.path.join(folder_path, new_name)\n",
    "    \n",
    "    # Renames the file\n",
    "    os.rename(old_file, new_file)\n",
    "\n",
    "print(\"Files renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Puts an number of files randomly from one folder to another folder\n",
    "def randomly_move_files(src_folder, dst_folder, num_files, move=True):\n",
    "\n",
    "    # Lists all files in the source folder\n",
    "    files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "    if len(files) < num_files:\n",
    "        print(f\"Not enough files in the source folder. Found {len(files)} files, but need {num_files}.\")\n",
    "        return\n",
    "\n",
    "    # Randomly selects the specified number of files\n",
    "    selected_files = random.sample(files, num_files)\n",
    "\n",
    "    # Moves or copies the selected files\n",
    "    for file_name in selected_files:\n",
    "        src_path = os.path.join(src_folder, file_name)\n",
    "        dst_path = os.path.join(dst_folder, file_name)\n",
    "        if move:\n",
    "            shutil.move(src_path, dst_path)\n",
    "        else:\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "    operation = \"moved\" if move else \"copied\"\n",
    "    print(f\"Successfully {operation} {num_files} files from {src_folder} to {dst_folder}.\")\n",
    "\n",
    "source_folder = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Test3\"\n",
    "destination_folder = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Fill_in_the_Middle/Train\"\n",
    "number_of_files = 18118\n",
    "\n",
    "randomly_move_files(source_folder, destination_folder, number_of_files, move=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles files in a folder and renames it in new order\n",
    "def shuffle_and_rename_files(path_r, path_w):\n",
    "    files = [f for f in os.listdir(path_r) if os.path.isfile(os.path.join(path_r, f))]\n",
    "    \n",
    "    random.shuffle(files)\n",
    "    \n",
    "    for i, file_name in enumerate(files, start=1):\n",
    "        old_path = os.path.join(path_r, file_name)\n",
    "        new_name = f\"solidity_code_{i}.sol\"\n",
    "        new_path = os.path.join(path_w, new_name)\n",
    "        \n",
    "        shutil.copy(old_path, new_path)\n",
    "        print(f\"Renamed: {file_name} -> {new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_path = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Fill_in_the_Middle\"\n",
    "new_path = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Test3\"\n",
    "shuffle_and_rename_files(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_line(path_r):\n",
    "    \n",
    "    with open(path_r, \"r\", encoding=\"utf-8\") as file:\n",
    "        solidity_code = file.read()\n",
    "\n",
    "    solidity_code = solidity_code.replace(\"    \", \"\\t\").replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").strip()\n",
    "\n",
    "    with open(path_r, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(solidity_code)\n",
    "\n",
    "path_r = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Test2/solidity_code_2696.sol\"\n",
    "to_one_line(path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Only_Constructs\"\n",
    "\n",
    "solidity_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "\n",
    "for file in solidity_files:\n",
    "    to_one_line(path_r=f\"D:/Uni_Ausbildung_Schule/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Final_Datasets/Dataset_Only_Constructs/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the folders\n",
    "# folder_path = r\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Splitted_Dataset\"\n",
    "# # folder_path2 = r\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Cleaned_Dataset\"\n",
    "# folder_path3 = r\"D:/TUHH_Computer_Science_Master/Forschungsprojekt/Preprocessing/Similarity_Dataset\"\n",
    "\n",
    "# file_pattern = \"*.sol\"\n",
    "\n",
    "# files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "# #files2 = glob.glob(os.path.join(folder_path2, file_pattern))\n",
    "# files3 = glob.glob(os.path.join(folder_path3, file_pattern))\n",
    "\n",
    "# for file in files:\n",
    "#     os.remove(file)\n",
    "#     #print(f\"{file} deleted!\")\n",
    "\n",
    "# # for file in files2:\n",
    "# #     os.remove(file)\n",
    "# #     #print(f\"{file} deleted!\")\n",
    "\n",
    "# for file in files3:\n",
    "#     os.remove(file)\n",
    "#     #print(f\"{file} deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolves some of the shadowing-local vulnerabilities from the low-vulnverability folder by renaming the owner identifier to accountOwner\n",
    "def rename_owner_in_functions(file_path, output_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        code = f.read()\n",
    "\n",
    "    # Regex to match the comment with a function directly below it and extract function signature and body\n",
    "    function_pattern = (\n",
    "        r\"(// WARNING Vulnerability.*?shadowing-local.*?function\\s+\\w+\\(.*?\\)\\s+.*?{.*?})\"\n",
    "    )\n",
    "    \n",
    "    # Callback function to process each match\n",
    "    def rename_owner(match):\n",
    "        function_header = match.group(1)\n",
    "        \n",
    "        updated_header = re.sub(r\"//.*\", \"\", function_header)\n",
    "\n",
    "        # Renames 'owner' to 'accountOwner'\n",
    "        updated_header = re.sub(r\"\\bowner\\b\", \"accountOwner\", updated_header)\n",
    "\n",
    "        return updated_header \n",
    "\n",
    "    # Applies the regex and renaming\n",
    "    updated_code = re.sub(function_pattern, rename_owner, code, flags=re.S)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(updated_code)\n",
    "    print(f\"Updated code written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the missing immutable and constant keywords for some statements (repairs optimization issues)\n",
    "def add_keyword(file_path, output_file):\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    modified_lines = []\n",
    "\n",
    "    # The comment pattern of an optimization issue\n",
    "    pattern_immutable = r\"// Recommendation for.*: Add the 'immutable'\"\n",
    "    pattern_constable = r\"// Recommendation for.*: Add the 'constant'\"\n",
    "\n",
    "    visibility_pattern = r\"\\b(public|private|internal|external)\\b\"\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        \n",
    "        # Inserts the first line\n",
    "        if i == 0:\n",
    "            modified_lines.append(lines[0])\n",
    "        if i+1 < len(lines):\n",
    "            next_line = lines[i + 1]\n",
    " \n",
    "        # Checks if the current line contains the pattern\n",
    "        if re.search(pattern_immutable, line) and i + 1 < len(lines):\n",
    "            # Processes the next line for the variable declaration\n",
    "            next_line = lines[i + 1]\n",
    "            if re.search(visibility_pattern, next_line) and \"immutable\" not in next_line:\n",
    "                modified_line = re.sub(r\"((public|private|internal|external)\\s+)\", r\"\\1immutable \", next_line)\n",
    "                modified_lines.append(modified_line)  \n",
    "                continue                              # Skips the line since it was already processed\n",
    "        \n",
    "        elif re.search(pattern_constable, line) and i + 1 < len(lines):\n",
    "            next_line = lines[i + 1]\n",
    "            if re.search(visibility_pattern, next_line) and \"constant\" not in next_line:\n",
    "                modified_line = re.sub(r\"((public|private|internal|external)\\s+)\", r\"\\1constant \", next_line)\n",
    "                modified_lines.append(modified_line)  \n",
    "                continue                              \n",
    "\n",
    "        modified_lines.append(next_line)\n",
    "    \n",
    "    # Deletes the last unnecessary line from the list\n",
    "    modified_lines.pop()\n",
    "    # Write the modified lines to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(modified_lines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
